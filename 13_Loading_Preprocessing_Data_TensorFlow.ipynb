{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.0 64-bit ('venv')",
      "metadata": {
        "interpreter": {
          "hash": "7b58ff03a81b7b220740b362f01ec4719380627cca970f4b363191d14b8c12ac"
        }
      }
    },
    "colab": {
      "name": "13_Loading_Preprocessing_Data_TensorFlow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh-BDFROrrlC"
      },
      "source": [
        "# Chapter 13: Loading and Preprocessing Data with TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2Xp4aRNsVSf"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrbI82TtzLnQ"
      },
      "source": [
        "Since Deep Learning systems are often trained on very large datasets that will not fit in RAM, TensorFlow's **Data API** solves this issue by taking care of all the implementation details and only needs:\n",
        "- A dataset object\n",
        "- Where to get the data\n",
        "- How to transform it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITP8mk7arrlF"
      },
      "source": [
        "## 13.1 The Data API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_i4gXmC5stZG"
      },
      "source": [
        "The Data API revolves around the concept of a **dataset**: a sequence of data items."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvSahjM8s3SU",
        "outputId": "572b99fd-58db-4ffe-ab1f-bfd2e3073534"
      },
      "source": [
        "# Create a dataset entirely in RAM\n",
        "X = tf.range(10) # any data tensor\n",
        "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (), types: tf.int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xj-6u4tatQuY"
      },
      "source": [
        "The `from_tensor_slices()` function takes a tensor and creates a `tf.data.Dataset` whose elements are all the slices of X. This is the same as `tf.data.Dataset.range(10)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8RIx3hutkst",
        "outputId": "d3341a91-d9e0-447d-d24f-8b3b49070447"
      },
      "source": [
        "# Iterate over dataset's items\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(3, shape=(), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n",
            "tf.Tensor(5, shape=(), dtype=int32)\n",
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "tf.Tensor(7, shape=(), dtype=int32)\n",
            "tf.Tensor(8, shape=(), dtype=int32)\n",
            "tf.Tensor(9, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1pXrKLlrrlG"
      },
      "source": [
        "### 13.1.1 Chaining Transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QmJqp6_t32e"
      },
      "source": [
        "Once you have a dataset, you can apply transformations by calling its transformation methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UV0TpO65t-gX",
        "outputId": "0555b6eb-1eb6-494f-8e1b-751d947559c2"
      },
      "source": [
        "# See Figure 13-1. Chaining dataset transformations\n",
        "dataset = dataset.repeat(3).batch(7)\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
            "tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
            "tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
            "tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
            "tf.Tensor([8 9], shape=(2,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_MvYsp4uqOA"
      },
      "source": [
        "With original dataset,\n",
        "1. Call `repeat(3)` to return a new dataset with 3 copies of the dataset.\n",
        "    - Calling with no arguments will result in a new dataset that repeats forever, so the code that iterates over the dataset must decide when to stop.\n",
        "\n",
        "2. Call `batch(7)` to return a new dataset that groups the items into batches of 7 items and any remaining items in the last batch (batch of 2).\n",
        "    - Add `drop_remainder=True` argument to drop this final batch.\n",
        "\n",
        "> Note: Dataset methods **do not** modify datasets; they create new ones (ie. assign with `dataset = ...`) or else nothing will happen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTBo5tcCwW9I",
        "outputId": "4e4c5611-957c-4679-841b-67f81cb4d8c7"
      },
      "source": [
        "# Creates new dataset with all items doubled\n",
        "dataset = dataset.map(lambda x: x * 2) # Items:[0,2,4,6,8,10,12]\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([ 0  2  4  6  8 10 12], shape=(7,), dtype=int32)\n",
            "tf.Tensor([14 16 18  0  2  4  6], shape=(7,), dtype=int32)\n",
            "tf.Tensor([ 8 10 12 14 16 18  0], shape=(7,), dtype=int32)\n",
            "tf.Tensor([ 2  4  6  8 10 12 14], shape=(7,), dtype=int32)\n",
            "tf.Tensor([16 18], shape=(2,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9sQk8RExFvR"
      },
      "source": [
        "While the `map()` method applies a transformation to each item, the `apply()` method applies a transformation to the dataset as a whole.\n",
        "\n",
        "> Note: `apply()` method is not used since `tf.data.Dataset.unbatch(dataset)` needs 1 argument for the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogyiShKtxSrt",
        "outputId": "791a5678-db61-427c-d4ea-1281dd6c0c2e"
      },
      "source": [
        "# tf.data.experimental.unbatch() is now deprecated\n",
        "# Use tf.data.Dataset.unbatch()\n",
        "# Each item in the new dataset will be single-integer tensor\n",
        "dataset = tf.data.Dataset.unbatch(dataset)\n",
        "\n",
        "# Filter the dataset\n",
        "dataset = dataset.filter(lambda x: x < 10) # Items: 0 2 4 6 8 0 2 4 6...\n",
        "\n",
        "# Look at just a few items from dataset\n",
        "for item in dataset.take(3):\n",
        "    print(item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(0, shape=(), dtype=int32)\n",
            "tf.Tensor(2, shape=(), dtype=int32)\n",
            "tf.Tensor(4, shape=(), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eqQ58KrrrlG"
      },
      "source": [
        "### 13.1.2 Shuffling the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZxXT6CbIJZU"
      },
      "source": [
        "Gradient Descent works best when the instances in the training set are independent and identically distributed (iid). A simple way to ensure this is to shuffle the instances, using the `shuffle()` method.\n",
        "\n",
        "> Note: You must specify the buffer size, and it's important to make it large enough, or else shuffling will not be very effective.\n",
        "\n",
        "> Note: By default, calling `repeat()` on a shuffled dataset will generate a new order at every iteration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLq55PaXIzB_",
        "outputId": "a1dea5ca-fd36-498d-fc5e-89a04d5c0ccf"
      },
      "source": [
        "dataset = tf.data.Dataset.range(10).repeat(3) # 0 to 9, three times\n",
        "dataset = dataset.shuffle(buffer_size=5, seed=42).batch(7)\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0 2 3 6 7 9 4], shape=(7,), dtype=int64)\n",
            "tf.Tensor([5 0 1 1 8 6 5], shape=(7,), dtype=int64)\n",
            "tf.Tensor([4 8 7 1 2 3 0], shape=(7,), dtype=int64)\n",
            "tf.Tensor([5 4 2 7 8 9 9], shape=(7,), dtype=int64)\n",
            "tf.Tensor([3 6], shape=(2,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yAEokUOJvy-"
      },
      "source": [
        "For large datasets, simple shuffling-buffer may not be enough; buffer size is still small compared to the large dataset.\n",
        "\n",
        "Some solutions are:\n",
        "- Shuffle the source data itself.\n",
        "- Split the source data into multiple files, then read them in a random order during training.\n",
        "- Pick multiple files randomly and read them simultaneously, interleaving their records.\n",
        "- Add a shuffling buffer on top of all that using `shuffle()` method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrTpfj6bKoNv"
      },
      "source": [
        "#### Interleaving lines from multiple files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GPeLYi2Lkq6",
        "outputId": "0a6b9c38-a7d4-4853-946f-32441182fc3d"
      },
      "source": [
        "# FROM TEXTBOOK NOTEBOOK\n",
        "# Load CA housing dataset\n",
        "# Split into training, validation, test set\n",
        "# Scale sets\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train_full, y_train_full, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_mean = scaler.mean_\n",
        "X_std = scaler.scale_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbE6z-DQMD9W"
      },
      "source": [
        "# FROM TEXTBOOK NOTEBOOK\n",
        "# Split housing set\n",
        "# Save into 20 CSV files\n",
        "\n",
        "def save_to_multiple_csv_files(data, name_prefix, header=None, n_parts=10):\n",
        "    housing_dir = os.path.join(\"datasets\", \"housing\")\n",
        "    os.makedirs(housing_dir, exist_ok=True)\n",
        "    path_format = os.path.join(housing_dir, \"my_{}_{:02d}.csv\")\n",
        "\n",
        "    filepaths = []\n",
        "    m = len(data)\n",
        "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
        "        part_csv = path_format.format(name_prefix, file_idx)\n",
        "        filepaths.append(part_csv)\n",
        "        with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
        "            if header is not None:\n",
        "                f.write(header)\n",
        "                f.write(\"\\n\")\n",
        "            for row_idx in row_indices:\n",
        "                f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
        "                f.write(\"\\n\")\n",
        "    return filepaths\n",
        "\n",
        "train_data = np.c_[X_train, y_train]\n",
        "valid_data = np.c_[X_valid, y_valid]\n",
        "test_data = np.c_[X_test, y_test]\n",
        "header_cols = housing.feature_names + [\"MedianHouseValue\"]\n",
        "header = \",\".join(header_cols)\n",
        "\n",
        "train_filepaths = save_to_multiple_csv_files(train_data, \"train\", header, n_parts=20)\n",
        "valid_filepaths = save_to_multiple_csv_files(valid_data, \"valid\", header, n_parts=10)\n",
        "test_filepaths = save_to_multiple_csv_files(test_data, \"test\", header, n_parts=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cAIIpUFMkkw",
        "outputId": "492a6533-d4ad-49db-c535-bb11f6cd08d7"
      },
      "source": [
        "# FROM TEXTBOOK NOTEBOOK\n",
        "# Read 1st few lines of CSV file in text mode\n",
        "\n",
        "with open(train_filepaths[0]) as f:\n",
        "    for i in range(5):\n",
        "        print(f.readline(), end=\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MedInc,HouseAge,AveRooms,AveBedrms,Population,AveOccup,Latitude,Longitude,MedianHouseValue\n",
            "3.5214,15.0,3.0499445061043287,1.106548279689234,1447.0,1.6059933407325193,37.63,-122.43,1.442\n",
            "5.3275,5.0,6.490059642147117,0.9910536779324056,3464.0,3.4433399602385686,33.69,-117.39,1.687\n",
            "3.1,29.0,7.5423728813559325,1.5915254237288134,1328.0,2.2508474576271187,38.44,-122.98,1.621\n",
            "7.1736,12.0,6.289002557544757,0.9974424552429667,1054.0,2.6956521739130435,33.55,-117.7,2.621\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHPJQfv8M3V-",
        "outputId": "1bc55c04-13c6-49c9-ac6e-c0c3c2934bac"
      },
      "source": [
        "train_filepaths"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['datasets/housing/my_train_00.csv',\n",
              " 'datasets/housing/my_train_01.csv',\n",
              " 'datasets/housing/my_train_02.csv',\n",
              " 'datasets/housing/my_train_03.csv',\n",
              " 'datasets/housing/my_train_04.csv',\n",
              " 'datasets/housing/my_train_05.csv',\n",
              " 'datasets/housing/my_train_06.csv',\n",
              " 'datasets/housing/my_train_07.csv',\n",
              " 'datasets/housing/my_train_08.csv',\n",
              " 'datasets/housing/my_train_09.csv',\n",
              " 'datasets/housing/my_train_10.csv',\n",
              " 'datasets/housing/my_train_11.csv',\n",
              " 'datasets/housing/my_train_12.csv',\n",
              " 'datasets/housing/my_train_13.csv',\n",
              " 'datasets/housing/my_train_14.csv',\n",
              " 'datasets/housing/my_train_15.csv',\n",
              " 'datasets/housing/my_train_16.csv',\n",
              " 'datasets/housing/my_train_17.csv',\n",
              " 'datasets/housing/my_train_18.csv',\n",
              " 'datasets/housing/my_train_19.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-a-mWbKM9zl"
      },
      "source": [
        "# Create dataset with only these file paths\n",
        "filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2nDVadGNLS9"
      },
      "source": [
        "> Note: By default, the `list_files()` function returns a dataset that shuffles the file paths.\n",
        "\n",
        "Next, call `interleave()` method to read from five files at a time and interleave their lines (skipping 1st line which is the header row)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgkeqN35Njg1"
      },
      "source": [
        "n_readers = 5\n",
        "dataset = filepath_dataset.interleave(\n",
        "    lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
        "    cycle_length=n_readers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOiOYMnwOAl_"
      },
      "source": [
        "At this stage, there will be 7 datasets in all:\n",
        "- The filepath dataset\n",
        "- The interleave dataset\n",
        "- 5 `TextLineDatasets` created internally by the interleave dataset.\n",
        "\n",
        "When iterating over the interleave set, it will cycle through these 5 `TextLineDatasets` reading one line at a time until all datasets are out of items. Then it will get the next 5 file paths from `filepath_dataset` and interleave them the same way until it runs out of file paths.\n",
        "\n",
        "By default, `interleave()` does not use parallelism; it just reads one line at a time from each file. To read files in parallel, set `num_parallel_calls` argument to the number of threads you want."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-O8ob8VLO6VO",
        "outputId": "70e5cdac-a7cb-487a-c3f5-bab20774a292"
      },
      "source": [
        "# 1st rows of 5 CSV files, chosen randomly\n",
        "\n",
        "for line in dataset.take(5):\n",
        "    print(line.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'4.2083,44.0,5.323204419889502,0.9171270718232044,846.0,2.3370165745856353,37.47,-122.2,2.782'\n",
            "b'4.1812,52.0,5.701388888888889,0.9965277777777778,692.0,2.4027777777777777,33.73,-118.31,3.215'\n",
            "b'3.6875,44.0,4.524475524475524,0.993006993006993,457.0,3.195804195804196,34.04,-118.15,1.625'\n",
            "b'3.3456,37.0,4.514084507042254,0.9084507042253521,458.0,3.2253521126760565,36.67,-121.7,2.526'\n",
            "b'3.5214,15.0,3.0499445061043287,1.106548279689234,1447.0,1.6059933407325193,37.63,-122.43,1.442'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXCb2tRurrlH"
      },
      "source": [
        "### 13.1.3 Preprocessing the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpaLJbKKPxVF"
      },
      "source": [
        "# X_mean, X_std = # mean and scale of each feature in the training set\n",
        "# X_mean, X_std already assigned when loading CA dataset\n",
        "\n",
        "n_inputs = 8\n",
        "\n",
        "def preprocess(line):\n",
        "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
        "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
        "    x = tf.stack(fields[:-1])\n",
        "    y = tf.stack(fields[-1:])\n",
        "    return (x - X_mean) / X_std, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L86Id5qlQoiv"
      },
      "source": [
        "Code explanation:\n",
        "\n",
        "1. (Line 1): Precomputed the mean and standard deviation of each feature in the training set.\n",
        "\n",
        "2. (Lines 6-8): The `preprocess()` function takes one CSV line and starts by parsing it.\n",
        "    - (Line 7): All feature columns are floats and missing values should default to 0. And provide an empty array of type `tf.float32` as the default value for the last column (the target).\n",
        "    - (Line 8): `tf.io.decode_csv()` function takes 2 arguments: the line to parse and an array containing the default value for each column in the CSV file.\n",
        "\n",
        "3. (Lines 9-10): `decode_csv()` function returns a list of scalar tensors (1 per column) but we need to return 1D tensor arrays.\n",
        "    - (Line 9): Call `tf.stack()` on all tensors except last one (the target) to stack tensors into a 1D array.\n",
        "    - (Line 10): Call `tf.stack()` on target value to stack into a 1D tensor array with a single value, rather than a scalar tensor.\n",
        "\n",
        "4. (Line 11): Scale the input features by subtracting the feature means `(x - X_mean)`, dividing by the feature standard deviation `/ X_std`, and return a tuple containing the scaled features and the target.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wANud2vYQbvk",
        "outputId": "6d04f511-fb2a-4819-c8d0-0475c597b114"
      },
      "source": [
        "# Test preprocessing function\n",
        "preprocess(b'4.2083,44.0,5.323204419889502,0.9171270718232044,846.0,2.3370165745856353,37.47,-122.2,2.782')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
              " array([ 0.16579159,  1.216324  , -0.05204396, -0.39210168, -0.5277444 ,\n",
              "        -0.26334172,  0.8543046 , -1.3072058 ], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.782], dtype=float32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0VBpPyrrrlH"
      },
      "source": [
        "### 13.1.4 Putting Everything Together"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7C9ebZO1PV2"
      },
      "source": [
        "Put everything together into a small helper function that will:\n",
        "- Create and return a dataset that will load CA housing data from multiple CSV files\n",
        "- Preprocess it\n",
        "- Shuffle it\n",
        "- Optionally repeat it\n",
        "- Batch it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov7Y6aMg1pSe"
      },
      "source": [
        "def csv_reader_dataset(filepaths, repeat=1, n_readers=5,\n",
        "                       n_read_threads=None, shuffle_buffer_size=10000,\n",
        "                       n_parse_threads=5, batch_size=32):\n",
        "    dataset = tf.data.Dataset.list_files(filepaths) # Create dataset from multiple CSV files\n",
        "    dataset = dataset.interleave(\n",
        "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
        "        cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
        "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads) # Calls preprocess function\n",
        "    dataset = dataset.shuffle(shuffle_buffer_size).repeat(repeat) # Shuffles dataset \"repeat\" times\n",
        "    return dataset.batch(batch_size).prefetch(1) # Important for performance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de7jQo1VrrlI"
      },
      "source": [
        "### 13.1.5 Prefetching"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJZulJyU3oV8"
      },
      "source": [
        "By calling `prefetch(1)` at the end, we are creating a dataset that will do its best to always be 1 (or multiple) batch(es) ahead. \n",
        "\n",
        "In other words, while our training algorithm is working on one batch, the dataset will already be working in parallel on getting the next batch ready (eg. reading the data from disk and preprocessing it).\n",
        "\n",
        "> Note: With prefetching, the CPU and GPU work in parallel: as the GPU works on one batch, the CPU works on the next.\n",
        "\n",
        "If the dataset is small enough to fit in memory, use dataset's `cache()` method to cache its content to RAM and speed up training. Do this **after** loading and preprocessing the data, but **before** shuffling, repeating, batching, and prefetching."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S214FBxerrlJ"
      },
      "source": [
        "### 13.1.6 Using the Dataset with tf.keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FW1gCFKy5swL"
      },
      "source": [
        "# Use csv_reader_dataset() to create sets\n",
        "train_set = csv_reader_dataset(train_filepaths)\n",
        "valid_set = csv_reader_dataset(valid_filepaths)\n",
        "test_set = csv_reader_dataset(test_filepaths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CBIUvJe6pVh",
        "outputId": "4da892dd-c99b-46b6-c808-f5e54e81ddb9"
      },
      "source": [
        "# From textbook notebook\n",
        "# Build and train Keras model\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
        "    keras.layers.Dense(1),\n",
        "])\n",
        "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
        "\n",
        "model.fit(train_set, epochs=10, validation_data=valid_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "363/363 [==============================] - 2s 3ms/step - loss: 3.0959 - val_loss: 3.8690\n",
            "Epoch 2/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 1.0523 - val_loss: 1.1137\n",
            "Epoch 3/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.8122 - val_loss: 0.7239\n",
            "Epoch 4/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.7343 - val_loss: 0.6612\n",
            "Epoch 5/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6527 - val_loss: 0.6517\n",
            "Epoch 6/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6341 - val_loss: 0.6310\n",
            "Epoch 7/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.6299 - val_loss: 0.6054\n",
            "Epoch 8/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5916 - val_loss: 0.5891\n",
            "Epoch 9/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5682 - val_loss: 0.5564\n",
            "Epoch 10/10\n",
            "363/363 [==============================] - 1s 2ms/step - loss: 0.5330 - val_loss: 0.5215\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5bcabb39d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDB6KiKu7AxE",
        "outputId": "b5e6411c-1892-427d-f3e5-bc71c055cc9a"
      },
      "source": [
        "# Evaluate on test set and make prediction\n",
        "model.evaluate(test_set)\n",
        "new_set = test_set.take(3).map(lambda X, y: X) # pretend we have 3 new instances\n",
        "model.predict(new_set) # a dataset containing new instances"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "162/162 [==============================] - 0s 1ms/step - loss: 0.5228\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.3385925 ],\n",
              "       [1.3566871 ],\n",
              "       [1.975553  ],\n",
              "       [1.1848876 ],\n",
              "       [1.5380412 ],\n",
              "       [2.5135336 ],\n",
              "       [2.2623162 ],\n",
              "       [1.2559526 ],\n",
              "       [2.6903954 ],\n",
              "       [2.714336  ],\n",
              "       [1.8362496 ],\n",
              "       [2.0574398 ],\n",
              "       [1.942119  ],\n",
              "       [2.411251  ],\n",
              "       [1.0365776 ],\n",
              "       [0.78242517],\n",
              "       [1.3213642 ],\n",
              "       [2.1210408 ],\n",
              "       [1.818429  ],\n",
              "       [2.685921  ],\n",
              "       [1.5517488 ],\n",
              "       [2.303208  ],\n",
              "       [2.1002278 ],\n",
              "       [1.8787147 ],\n",
              "       [1.8928831 ],\n",
              "       [2.6535788 ],\n",
              "       [2.1432931 ],\n",
              "       [1.6555791 ],\n",
              "       [2.926011  ],\n",
              "       [3.245479  ],\n",
              "       [1.0477158 ],\n",
              "       [0.85796463],\n",
              "       [1.278811  ],\n",
              "       [1.5953363 ],\n",
              "       [1.6979065 ],\n",
              "       [3.4787908 ],\n",
              "       [1.5887406 ],\n",
              "       [2.496935  ],\n",
              "       [3.0445418 ],\n",
              "       [2.0707269 ],\n",
              "       [2.5267224 ],\n",
              "       [2.5330534 ],\n",
              "       [3.4804492 ],\n",
              "       [0.77085966],\n",
              "       [3.8585725 ],\n",
              "       [1.5676365 ],\n",
              "       [3.6967864 ],\n",
              "       [1.776646  ],\n",
              "       [1.9306016 ],\n",
              "       [1.2505447 ],\n",
              "       [2.44846   ],\n",
              "       [2.4583907 ],\n",
              "       [1.1052907 ],\n",
              "       [2.2794266 ],\n",
              "       [2.4463267 ],\n",
              "       [2.7751799 ],\n",
              "       [0.9593088 ],\n",
              "       [1.3960657 ],\n",
              "       [1.0992378 ],\n",
              "       [1.1609217 ],\n",
              "       [1.5225141 ],\n",
              "       [1.6614828 ],\n",
              "       [1.6341687 ],\n",
              "       [2.9423337 ],\n",
              "       [2.1151907 ],\n",
              "       [1.0627215 ],\n",
              "       [2.5984626 ],\n",
              "       [2.814077  ],\n",
              "       [0.59269845],\n",
              "       [2.2759132 ],\n",
              "       [2.1180294 ],\n",
              "       [5.558236  ],\n",
              "       [1.8572055 ],\n",
              "       [1.9872177 ],\n",
              "       [0.96959066],\n",
              "       [1.6656854 ],\n",
              "       [2.6435957 ],\n",
              "       [1.1506864 ],\n",
              "       [1.5844939 ],\n",
              "       [2.3743312 ],\n",
              "       [6.325423  ],\n",
              "       [1.6709833 ],\n",
              "       [1.3414682 ],\n",
              "       [2.002791  ],\n",
              "       [1.6535814 ],\n",
              "       [0.6405405 ],\n",
              "       [1.6653508 ],\n",
              "       [2.3194337 ],\n",
              "       [3.7059941 ],\n",
              "       [1.9020087 ],\n",
              "       [2.8478203 ],\n",
              "       [2.7843728 ],\n",
              "       [1.4878148 ],\n",
              "       [1.5322847 ],\n",
              "       [1.9400336 ],\n",
              "       [2.141818  ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GE4uhVD8B-_"
      },
      "source": [
        "# FROM TEXTBOOK NOTEBOOK\n",
        "\n",
        "# To build custom training loop,\n",
        "# iterate over the training set\n",
        "optimizer = keras.optimizers.Nadam(lr=0.01)\n",
        "loss_fn = keras.losses.mean_squared_error\n",
        "\n",
        "global_step = 0\n",
        "for X_batch, y_batch in train_set:\n",
        "    global_step += 1\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = model(X_batch)\n",
        "        main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
        "        loss = tf.add_n([main_loss] + model.losses)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuSnDhqg9lFq"
      },
      "source": [
        "# FROM TEXTBOOK NOTEBOOK\n",
        "\n",
        "# TF Function that performs the whole training loop\n",
        "optimizer = keras.optimizers.Nadam(lr=0.01)\n",
        "loss_fn = keras.losses.mean_squared_error\n",
        "\n",
        "@tf.function\n",
        "def train(model, n_epochs, batch_size=32,\n",
        "          n_readers=5, n_read_threads=5, shuffle_buffer_size=10000, n_parse_threads=5):\n",
        "    train_set = csv_reader_dataset(train_filepaths, repeat=n_epochs, n_readers=n_readers,\n",
        "                       n_read_threads=n_read_threads, shuffle_buffer_size=shuffle_buffer_size,\n",
        "                       n_parse_threads=n_parse_threads, batch_size=batch_size)\n",
        "    for X_batch, y_batch in train_set:\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = model(X_batch)\n",
        "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
        "            loss = tf.add_n([main_loss] + model.losses)\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "train(model, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9cVdvOYrrlJ"
      },
      "source": [
        "## 13.2 The TFRecord Format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo5rhyMXQGVj"
      },
      "source": [
        "The TFRecord format is TensorFlow's preferred format for storing large amounts of data and reading it efficiently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0c4eGc0Qyp_"
      },
      "source": [
        "# Create a TFRecord file\n",
        "with tf.io.TFRecordWriter(\"my_data.tfrecord\") as f:\n",
        "    f.write(b\"This is the first record\")\n",
        "    f.write(b\"And this is the second record\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nflaI38iRD6P",
        "outputId": "088d8de6-2ed4-4ec8-b369-33685bd40dad"
      },
      "source": [
        "# Read TFRecord file\n",
        "filepaths = [\"my_data.tfrecord\"]\n",
        "dataset = tf.data.TFRecordDataset(filepaths)\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'This is the first record', shape=(), dtype=string)\n",
            "tf.Tensor(b'And this is the second record', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsCswQNMrrlL"
      },
      "source": [
        "### 13.2.1 Compressed TFRecord Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxiTWVQZRdqf"
      },
      "source": [
        "To create a compressed TFRecord file, set the options argument."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auyxcAUBRhV2"
      },
      "source": [
        "# Create a compressed TFRecord file\n",
        "options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
        "with tf.io.TFRecordWriter(\"my_compressed.tfrecord\", options) as f:\n",
        "    f.write(b\"This is the first record\")\n",
        "    f.write(b\"And this is the second record\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16QFii2IR4xa",
        "outputId": "c33fa997-ac9e-47ba-b119-1b65afccf29d"
      },
      "source": [
        "# Read a compressed TFRecord file\n",
        "dataset = tf.data.TFRecordDataset([\"my_compressed.tfrecord\"],\n",
        "                                  compression_type=\"GZIP\")\n",
        "for item in dataset:\n",
        "    print(item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(b'This is the first record', shape=(), dtype=string)\n",
            "tf.Tensor(b'And this is the second record', shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ux4lBCsSrrlM"
      },
      "source": [
        "### 13.2.2 A Brief Introduction to Protocol Buffers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pITcwJ5kSX0Z"
      },
      "source": [
        "TFRecord files usually contain serialized **protocol buffers** (also called **protobufs**). This is a portable, extensible, and efficient binary format developed at Google."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8Fnsn6USnSz",
        "outputId": "9ffdd6ea-cefc-452c-fbb8-7b808a435e2e"
      },
      "source": [
        "# protobuf defined that looks like\n",
        "# from textbook notebook \n",
        "%%writefile person.proto\n",
        "syntax = \"proto3\";\n",
        "message Person {\n",
        "    string name = 1;\n",
        "    int32 id = 2;\n",
        "    repeated string email = 3;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing person.proto\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8pFaJ6PTSQ5"
      },
      "source": [
        "Definition explanation:\n",
        "\n",
        "1. (Line 3): We are using version 3 of the protobuf format\n",
        "\n",
        "2. (Line 4): Protobuf objects are meant to be serialized and transmitted, therefore are called *messages*.\n",
        "\n",
        "3. (Lines 5-7): The \"contents\" of the protobuf object\n",
        "    - The numbers `1, 2, 3` are the field identifiers: they will be used in each record's binary representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7ji6f55WfaZ"
      },
      "source": [
        "# FROM TEXTBOOK NOTEBOOK\n",
        "!protoc person.proto --python_out=. # importing protobuf compiler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDW0r6SAURxl"
      },
      "source": [
        "# Using access classes generated for Person protobuf\n",
        "from person_pb2 import Person # import the generated access class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcazSxghXI2J",
        "outputId": "e967a891-664b-46e3-b791-b8aefaf9469b"
      },
      "source": [
        "person = Person(name=\"Al\", id=123, email=[\"a@b.com\"]) # create a Person\n",
        "print(person) # display the Person"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "name: \"Al\"\n",
            "id: 123\n",
            "email: \"a@b.com\"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Mu5mipCXX1UK",
        "outputId": "bd2c7389-5374-4cc5-a78b-7a5a8a94174a"
      },
      "source": [
        "person.name # read a field"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Al'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1j5ddz1MX4Ht",
        "outputId": "37ad9cdb-51e1-494a-90e0-3b9eac49e2e5"
      },
      "source": [
        "person.name = \"Alice\" # modify a field\n",
        "person.email[0] # repeated fields can be accessed like arrays"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'a@b.com'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHVqznzBX_z9",
        "outputId": "9afa81c2-7785-4ae1-fe98-cd13f0e934f9"
      },
      "source": [
        "person.email.append(\"c@d.com\") # add an email address\n",
        "s = person.SerializeToString() # serialize the object to a byte string\n",
        "s"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'\\n\\x05Alice\\x10{\\x1a\\x07a@b.com\\x1a\\x07c@d.com'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbkmzaaTYQO1",
        "outputId": "d23b7ab0-8a5a-4120-fd16-19780abb6b9e"
      },
      "source": [
        "person2 = Person() # create a new Person\n",
        "person2.ParseFromString(s) # parse the byte string (27 bytes long)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYU3ls1iYfkW",
        "outputId": "27ddccfb-57ec-4ca9-ed05-0840f4a18b08"
      },
      "source": [
        "person == person2 # now they are equal"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvO5FlmhYy6F"
      },
      "source": [
        "To summarize,\n",
        "1. Import `Person` class generated by protoc.\n",
        "2. Create an instance and visualize it, read/write some fields.\n",
        "3. Serialize it using `SerializeToString()` method.\n",
        "4. To read and parse the binary data, use `ParseFromString()` method.\n",
        "5. Returns a copy of the object that was serialized.\n",
        "\n",
        "> Note: Since these operations are not TensorFlow operations, they cannot be included in a TensorFlow Function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9orkoC-hrrlO"
      },
      "source": [
        "### 13.2.3 TensorFlow Protobufs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp6-s231Z6UO"
      },
      "source": [
        "The main protobuf typically used in a TFRecord file is the `Example` protobuf, which represents one instance in a dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uitAeOC4aDAZ",
        "outputId": "e9991dd1-8c47-46e5-de0a-955173af09dd"
      },
      "source": [
        "# Example protobuf definition\n",
        "# %%writefile so no error\n",
        "%%writefile Example.proto\n",
        "syntax = \"proto3\";\n",
        "message BytesList { repeated bytes value = 1;}\n",
        "message FloatList { repeated float value = 1 [packed = true]; }\n",
        "message Int64List { repeated int64 value = 1 [packed = true]; }\n",
        "message Feature {\n",
        "    oneof kind {\n",
        "        BytesList bytes_list = 1;\n",
        "        FloatList float_list = 2;\n",
        "        Int64List int64_list = 3;\n",
        "    }\n",
        "};\n",
        "message Features { map<string, Feature> feature = 1; };\n",
        "message Example { Features features = 1; };"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing Example.proto\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5FuAWYweYaj"
      },
      "source": [
        "Definition explanation:\n",
        "\n",
        "- (Lines 6 & 7): `[packed = true]` is used for repeated numerical fields, for a more efficient encoding.\n",
        "\n",
        "- (Lines 8-14): A `Feature` contains either a `BytesList`, a `FloatList`, or an `Int64List`.\n",
        "\n",
        "- (Line 15): A `Features` contains a **dictionary** that maps a feature name to the corresponding feature value.\n",
        "\n",
        "- (Line 16): An `Example` only contains a `Features` object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHJ3Jh6Gfe7o"
      },
      "source": [
        "\"\"\"Create a tf.train.Example\n",
        "representing the same person as earlier\n",
        "and write it to a TFRecord file.\"\"\"\n",
        "from tensorflow.train import BytesList, FloatList, Int64List\n",
        "from tensorflow.train import Feature, Features, Example"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcMxFPxgf6nv"
      },
      "source": [
        "person_example = Example(\n",
        "    features=Features(\n",
        "        feature={\n",
        "            \"name\": Feature(bytes_list=BytesList(value=[b\"Alice\"])),\n",
        "            \"id\": Feature(int64_list=Int64List(value=[123])),\n",
        "            \"emails\": Feature(bytes_list=BytesList(value=[b\"a@b.com\",\n",
        "                                                          b\"c@d.com\"]))\n",
        "        }\n",
        "    )\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyj73ZAagvxN"
      },
      "source": [
        "with tf.io.TFRecordWriter(\"my_contacts.tfrecord\") as f:\n",
        "    f.write(person_example.SerializeToString())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-UY2DdorrlP"
      },
      "source": [
        "### 13.2.4 Loading and Parsing Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ep2KPm63i2pq"
      },
      "source": [
        "To load the serialized `Example` protobufs, we will use a `tf.data.TFRecordDataset` once again, and parse each `Example` using `tf.io.parse_single_example()`. Since this is a TensorFlow operation, it will be included in a TF Function.\n",
        "\n",
        "It requires at least 2 arguments:\n",
        "\n",
        "1. A string scalar tensor containing the serialized data\n",
        "2. A description of each feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdkHxItPjiXl",
        "outputId": "5d7619f9-5dd3-4c33-f9da-e982af4e61c6"
      },
      "source": [
        "\"\"\"Define a description dictionary.\n",
        "Then iterate over the TFRecord Dataset,\n",
        "and parse the serialized Example protobuf.\"\"\"\n",
        "\n",
        "feature_description = {\n",
        "    \"name\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
        "    \"id\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
        "    \"emails\": tf.io.VarLenFeature(tf.string)\n",
        "}\n",
        "\n",
        "for serialized_example in tf.data.TFRecordDataset([\"my_contacts.tfrecord\"]):\n",
        "    parsed_example = tf.io.parse_single_example(serialized_example,\n",
        "                                                feature_description)\n",
        "parsed_example"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'emails': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7f474500f310>,\n",
              " 'id': <tf.Tensor: shape=(), dtype=int64, numpy=123>,\n",
              " 'name': <tf.Tensor: shape=(), dtype=string, numpy=b'Alice'>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-_E0BEXktVE",
        "outputId": "a13c560f-9f23-4d91-dac6-f50b7be78582"
      },
      "source": [
        "# Variable-length features are parsed as sparse tensors\n",
        "tf.sparse.to_dense(parsed_example[\"emails\"], default_value=b\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'a@b.com', b'c@d.com'], dtype=object)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13klRY26lLxK",
        "outputId": "c2886503-f248-460c-9624-8f957a52219f"
      },
      "source": [
        "# Simpler to access its values\n",
        "parsed_example[\"emails\"].values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b'a@b.com', b'c@d.com'], dtype=object)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ib5WjvTlmjg"
      },
      "source": [
        "A `BytesList` can contain any binary data you want.\n",
        "\n",
        "- Encode an image using JPEG format and `tf.io.encode_jpeg()`  and put this binary data in a `BytesList`.\n",
        "\n",
        "- Then when reading, it was parse the `Example` and then call `tf.io.decode_jpeg()` or `tf.io.decode_image()` to decode the image.\n",
        "\n",
        "- Store any tensor by serializing it using `tf.io.serialize_tensor()` then put the resulting byte string in a `BytesList` feature.\n",
        "\n",
        "- Then parse using `tf.io.parse_tensor()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBQwDATHmure",
        "outputId": "673a94c0-2985-48c0-e685-697fbf269a24"
      },
      "source": [
        "# Parse batch by batch\n",
        "dataset = tf.data.TFRecordDataset([\"my_contacts.tfrecord\"]).batch(10)\n",
        "for serialized_examples in dataset:\n",
        "    parsed_examples = tf.io.parse_example(serialized_examples,\n",
        "                                          feature_description)\n",
        "parsed_examples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'emails': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7f4745016550>,\n",
              " 'id': <tf.Tensor: shape=(1,), dtype=int64, numpy=array([123])>,\n",
              " 'name': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'Alice'], dtype=object)>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GreUVz2inLS6"
      },
      "source": [
        "> Note: The `Example` protobuf is sufficient for most use cases, except when dealing with lists of lists."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_N5mt_hrrlP"
      },
      "source": [
        "### 13.2.5 Handling Lists of Lists Using the SequenceExample Protobuf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2Pi16wxnaYQ",
        "outputId": "df790e2d-7c1e-40de-87d3-17357227b448"
      },
      "source": [
        "# %%writefile so no error\n",
        "%%writefile SequenceExample.proto\n",
        "message FeatureList { repeated Feature feature = 1; };\n",
        "message FeatureLists { map<string, FeatureList> feature_list = 1; };\n",
        "message SequenceExample {\n",
        "    Features context = 1;\n",
        "    FeatureLists feature_lists = 2;\n",
        "};"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing SequenceExample.proto\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTReiGnEoO0_"
      },
      "source": [
        "Definition explanation:\n",
        "\n",
        "- (Line 5-7): A `SequenceExample` contains:\n",
        "    - A `Features` object for the contextual data\n",
        "    - A `FeatureLists` object that contains one or more named `FeatureList` objects (eg. a `FeatureList` named `\"content\"` and another named `\"comments\"`).\n",
        "\n",
        "- (Line 3): Each `FeatureList` contains a list of `Feature` objects.\n",
        "\n",
        "Building, serializing, and parsing a `SequenceExample` is similar to that of `Example` but you must use `tf.io.parse_single_sequence_example()` or `tf.io.parse_sequence_example()` to parse a single or batch.\n",
        "\n",
        "> Note: If the feature lists contain sequences of varying sizes, you may want to convert them to ragged tensors using `tf.RaggedTensor.from_sparse()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CRaQW4Fqtn1"
      },
      "source": [
        "# FROM TEXTBOOK NOTEBOOK\n",
        "\n",
        "#from tensorflow.train import FeatureList, FeatureLists, SequenceExample\n",
        "FeatureList = tf.train.FeatureList\n",
        "FeatureLists = tf.train.FeatureLists\n",
        "SequenceExample = tf.train.SequenceExample\n",
        "\n",
        "context = Features(feature={\n",
        "    \"author_id\": Feature(int64_list=Int64List(value=[123])),\n",
        "    \"title\": Feature(bytes_list=BytesList(value=[b\"A\", b\"desert\", b\"place\", b\".\"])),\n",
        "    \"pub_date\": Feature(int64_list=Int64List(value=[1623, 12, 25]))\n",
        "})\n",
        "\n",
        "content = [[\"When\", \"shall\", \"we\", \"three\", \"meet\", \"again\", \"?\"],\n",
        "           [\"In\", \"thunder\", \",\", \"lightning\", \",\", \"or\", \"in\", \"rain\", \"?\"]]\n",
        "comments = [[\"When\", \"the\", \"hurlyburly\", \"'s\", \"done\", \".\"],\n",
        "            [\"When\", \"the\", \"battle\", \"'s\", \"lost\", \"and\", \"won\", \".\"]]\n",
        "\n",
        "def words_to_feature(words):\n",
        "    return Feature(bytes_list=BytesList(value=[word.encode(\"utf-8\")\n",
        "                                               for word in words]))\n",
        "\n",
        "content_features = [words_to_feature(sentence) for sentence in content]\n",
        "comments_features = [words_to_feature(comment) for comment in comments]\n",
        "            \n",
        "sequence_example = SequenceExample(\n",
        "    context=context,\n",
        "    feature_lists=FeatureLists(feature_list={\n",
        "        \"content\": FeatureList(feature=content_features),\n",
        "        \"comments\": FeatureList(feature=comments_features)\n",
        "    }))\n",
        "\n",
        "serialized_sequence_example = sequence_example.SerializeToString()\n",
        "\n",
        "context_feature_descriptions = {\n",
        "    \"author_id\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
        "    \"title\": tf.io.VarLenFeature(tf.string),\n",
        "    \"pub_date\": tf.io.FixedLenFeature([3], tf.int64, default_value=[0, 0, 0]),\n",
        "}\n",
        "sequence_feature_descriptions = {\n",
        "    \"content\": tf.io.VarLenFeature(tf.string),\n",
        "    \"comments\": tf.io.VarLenFeature(tf.string),\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdA8q281p-I-",
        "outputId": "5372672f-d6da-406a-9222-6624e119cc83"
      },
      "source": [
        "parsed_context, parsed_feature_lists = tf.io.parse_single_sequence_example(\n",
        "    serialized_sequence_example, context_feature_descriptions,\n",
        "    sequence_feature_descriptions\n",
        ")\n",
        "parsed_content = tf.RaggedTensor.from_sparse(parsed_feature_lists[\"content\"])\n",
        "parsed_content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'When', b'shall', b'we', b'three', b'meet', b'again', b'?'], [b'In', b'thunder', b',', b'lightning', b',', b'or', b'in', b'rain', b'?']]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iOTJwEQrrlP"
      },
      "source": [
        "## 13.3 Preprocessing the Input Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHi8_vQoxbxz"
      },
      "source": [
        "Preparing your data for a neural network requires converting all features into numerical features, generally normalizing them, and more. You can include a preprocessing layer directly in your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOBEEyPcxmrX"
      },
      "source": [
        "\"\"\"Implement a standardization layer using a Lambda layer.\n",
        "For each feature, it subtracts the mean and divides by its\n",
        "standard deviation (plus a smoothing term).\"\"\"\n",
        "means = np.mean(X_train, axis=0, keepdims=True)\n",
        "stds = np.std(X_train, axis=0, keepdims=True)\n",
        "eps = keras.backend.epsilon()\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Lambda(lambda imputs: (inputs - means) / (stds + eps)),\n",
        "    # other layers\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NglSFmyOy8sm"
      },
      "source": [
        "# A self-contained custom layer\n",
        "# like Scikit-Learn's StandardScalar\n",
        "class Standardization(keras.layers.Layer):\n",
        "    def adapt(self, data_sample):\n",
        "        self.means_ = np.mean(data_sample, axis=0, keepdims=True)\n",
        "        self.stds_ = np.std(data_sample, axis=0, keepdims=True)\n",
        "    def call(self, inputs):\n",
        "        return (inputs - self.means_) / (self.stds + keras.backend.epsilon())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "md5SuhJWzyNs"
      },
      "source": [
        "Before you can use this standardization layer, you will need to adapt it to your dataset by calling the `adapt()` method and passing it a data sample. This will allow it to use the appropriate mean and standard deviation for each feature.\n",
        "\n",
        "> Note: The sample must be large enough to be representative of your dataset, but it does not have to be the full training set: a few hundred randomly selected instances will suffice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5XJBN8j0AkD"
      },
      "source": [
        "std_layer = Standardization()\n",
        "std_layer.adapt(X_train) # Input X_train for data_sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irVpG2si08qA"
      },
      "source": [
        "# Use preprocessing layer like a normal layer\n",
        "model = keras.Sequential()\n",
        "model.add(std_layer)\n",
        "# create the rest of the model\n",
        "# model.compile()\n",
        "# model.fit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi459OyWrrlQ"
      },
      "source": [
        "### 13.3.1 Encoding Categorical Features Using One-Hot Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ICBILO8z2JMC",
        "outputId": "bb10a7c3-0d58-489d-d168-372a07b3d596"
      },
      "source": [
        "# FROM TEXTBOOK NOTEBOOK\n",
        "# Import CA housing set from Chapter 2\n",
        "import os\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
        "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
        "\n",
        "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
        "    os.makedirs(housing_path, exist_ok=True)\n",
        "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
        "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
        "    housing_tgz = tarfile.open(tgz_path)\n",
        "    housing_tgz.extractall(path=housing_path)\n",
        "    housing_tgz.close()\n",
        "\n",
        "fetch_housing_data()\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def load_housing_data(housing_path=HOUSING_PATH):\n",
        "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
        "    return pd.read_csv(csv_path)\n",
        "\n",
        "housing = load_housing_data()\n",
        "housing.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "      <th>ocean_proximity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-122.23</td>\n",
              "      <td>37.88</td>\n",
              "      <td>41.0</td>\n",
              "      <td>880.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>8.3252</td>\n",
              "      <td>452600.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-122.22</td>\n",
              "      <td>37.86</td>\n",
              "      <td>21.0</td>\n",
              "      <td>7099.0</td>\n",
              "      <td>1106.0</td>\n",
              "      <td>2401.0</td>\n",
              "      <td>1138.0</td>\n",
              "      <td>8.3014</td>\n",
              "      <td>358500.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-122.24</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1467.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>496.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>7.2574</td>\n",
              "      <td>352100.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-122.25</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1274.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>558.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>5.6431</td>\n",
              "      <td>341300.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-122.25</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1627.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>565.0</td>\n",
              "      <td>259.0</td>\n",
              "      <td>3.8462</td>\n",
              "      <td>342200.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   longitude  latitude  ...  median_house_value  ocean_proximity\n",
              "0    -122.23     37.88  ...            452600.0         NEAR BAY\n",
              "1    -122.22     37.86  ...            358500.0         NEAR BAY\n",
              "2    -122.24     37.85  ...            352100.0         NEAR BAY\n",
              "3    -122.25     37.85  ...            341300.0         NEAR BAY\n",
              "4    -122.25     37.85  ...            342200.0         NEAR BAY\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7H07eWCj2sAJ"
      },
      "source": [
        "The `ocean_proximity` feature is a categorical feature with 5 possible values: `\"<1H OCEAN\"`, `\"INLAND\"`, `\"NEAR OCEAN\"`, `\"NEAR BAY\"`, `\"ISLAND\"`. We can use one-hot encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVKtzucl2mG9"
      },
      "source": [
        "\"\"\"Use one-hot encoding by mapping each category to its index (0-4),\n",
        "which can be done using a lookup table.\"\"\"\n",
        "\n",
        "vocab = [\"<1H OCEAN\", \"INLAND\", \"NEAR OCEAN\", \"NEAR BAY\", \"ISLAND\"]\n",
        "indices = tf.range(len(vocab), dtype=tf.int64)\n",
        "table_init = tf.lookup.KeyValueTensorInitializer(vocab, indices)\n",
        "num_oov_buckets = 2\n",
        "table = tf.lookup.StaticVocabularyTable(table_init, num_oov_buckets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkHebVFk3xFw"
      },
      "source": [
        "Code Explanation:\n",
        "\n",
        "- (Line 4): Define the **vocabulary**: the list of all possible categories.\n",
        "\n",
        "- (Line 5): Create a tensor with the corresponding indices (0-4).\n",
        "\n",
        "- (Line 6): Create an initializer for the lookup table, passing the list of categories and corresponding indices.\n",
        "    - Since we already have this data, use `KeyValueTensorInitializer`.\n",
        "    - If categories are listed in text file, use `TextFileInitializer`.\n",
        "\n",
        "- (Line 7): Specify the number of **out-of-vocabulary** (oov) buckets.\n",
        "\n",
        "- (Line 8): Create the lookup table, passing the initializer and number of oov buckets.\n",
        "    - The indices of the two oov buckets are 5 and 6.\n",
        "    - If we look up a category that does not exist in the vocabulary, the lookup table will compute a hash and assign the unknown category to one of the oov buckets.\n",
        "\n",
        "Why use oov buckets?\n",
        "\n",
        "- If the number of categories is large and the dataset is also large, then getting the full list of categories may not be convenient.\n",
        "\n",
        "- One solution is to define the vocabulary based on a data sample and add some oov buckets for categories not in the data sample.\n",
        "\n",
        "- If there are not enough oov buckets, there will be collisions: different categories will end up in the same bucket."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B90MLHwV6kBa",
        "outputId": "03cb3f49-1058-4014-d861-6fac4f3504b4"
      },
      "source": [
        "\"\"\"Use the lookup table to encode a small batch of\n",
        "categorical features to one-hot vectors.\"\"\"\n",
        "\n",
        "categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\"])\n",
        "cat_indices = table.lookup(categories)\n",
        "cat_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([3, 5, 1, 1])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMmlSxbd7Dwq",
        "outputId": "7d0b4e75-9c5d-4883-bf5f-1f3594a2f48c"
      },
      "source": [
        "cat_one_hot = tf.one_hot(cat_indices, depth=len(vocab) + num_oov_buckets)\n",
        "cat_one_hot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 7), dtype=float32, numpy=\n",
              "array([[0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baQAl9Iz8KAR"
      },
      "source": [
        "> Note: When using `tf.one_hot()` we must tell this function the total number of indices, which is equal to the vocabulary size plus the number of oov buckets.\n",
        "\n",
        "> Note:  \n",
        "If the $\\text{num_categories} < 10$, use one-hot encoding.  \n",
        "If the $\\text{num_categories} > 50$, use embeddings.  \n",
        "If the $10 < \\text{num_categories} < 50$, experiment with both and see which works best."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqiTx2-grrlQ"
      },
      "source": [
        "### 13.3.2 Encoding Categorical Features Using Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jv9oBeqTRnMd"
      },
      "source": [
        "An embedding is a trainable dense vector that represents a category and is initialized randomly by default. Gradient Descent will end up pushing similar categories together and dissimilar categories apart.\n",
        "\n",
        "**Representation learning** - The better the representation, the easier it will be for the neural network to make accurate predictions, so training tends to make embeddings useful representations of the categories.\n",
        "\n",
        "> #### Word Embeddings\n",
        "\n",
        "> **Word embeddings** (ie. embeddings of individual words) - When you are working on a natural language processing task, you are often better off reusing pretrained word embeddings than training your own.\n",
        "\n",
        "> If you compute $\\text{King} - \\text{Man} + \\text{Woman} \\approx \\text{Queen}$, where you add and subtract the embedding vectors of these words. The word embeddings encode the concept of gender. Though it can also learn that Man is to Doctor as Woman is to Nurse, a sexist bias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73fuBBB9Wg1F",
        "outputId": "000fa96e-1017-4bc4-a70b-a402a44d369a"
      },
      "source": [
        "\"\"\"Create an embedding matrix containing\n",
        "each category's embedding, initialized randomly.\n",
        "1 row per category and oov bucket.\n",
        "1 column per embedding dimension.\"\"\"\n",
        "\n",
        "embedding_dim = 2 # typically 10-300 dimensions and can be tuned\n",
        "embed_init = tf.random.uniform([len(vocab) + num_oov_buckets, embedding_dim])\n",
        "embedding_matrix = tf.Variable(embed_init) # stored as variable so GD can modify its value\n",
        "embedding_matrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(7, 2) dtype=float32, numpy=\n",
              "array([[0.2116456 , 0.8795754 ],\n",
              "       [0.08010566, 0.8931905 ],\n",
              "       [0.06261468, 0.8572016 ],\n",
              "       [0.26212156, 0.4594009 ],\n",
              "       [0.0996958 , 0.52460384],\n",
              "       [0.7878139 , 0.29511285],\n",
              "       [0.79255724, 0.19892442]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2lL0IUJX_eN",
        "outputId": "ba43505f-f2f4-46ef-dbf6-a4e07cce1258"
      },
      "source": [
        "categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\"])\n",
        "cat_indices = table.lookup(categories)\n",
        "cat_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([3, 5, 1, 1])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5VQS83YYN3m",
        "outputId": "04e575b4-47f2-46d1-c1bb-274ccf8a671f"
      },
      "source": [
        "\"\"\"\"Look up the rows in the embedding matrix at the given indices.\"\"\"\n",
        "tf.nn.embedding_lookup(embedding_matrix, cat_indices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
              "array([[0.26212156, 0.4594009 ],\n",
              "       [0.7878139 , 0.29511285],\n",
              "       [0.08010566, 0.8931905 ],\n",
              "       [0.08010566, 0.8931905 ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kt-0lcm4ZR-m"
      },
      "source": [
        "Keras provides `keras.layers.Embedding` layer that handles the embedding matrix.\n",
        "\n",
        "- When the layer is created, it initializes the embedding matrix randomly.\n",
        "\n",
        "- When it is called with some category indices, it returns the rows at those indices in the embedding matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNQ4V1ocY--t",
        "outputId": "02d3f02a-ca7d-4d78-ec01-c54a774a13cb"
      },
      "source": [
        "embedding = keras.layers.Embedding(input_dim=len(vocab) + num_oov_buckets,\n",
        "                                   output_dim=embedding_dim)\n",
        "embedding(cat_indices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
              "array([[-0.04490776, -0.00843811],\n",
              "       [ 0.033209  ,  0.02249206],\n",
              "       [ 0.00212266,  0.03049174],\n",
              "       [ 0.00212266,  0.03049174]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPH7ajHbaHUi"
      },
      "source": [
        "\"\"\"Create a Keras model that process categorical features\n",
        "(along with regular numerical features)\n",
        "and learn an embedding for each category\n",
        "(as well as for each oov bucket).\"\"\"\n",
        "\n",
        "regular_inputs = keras.layers.Input(shape=[8])\n",
        "categories = keras.layers.Input(shape=[], dtype=tf.string)\n",
        "cat_indices = keras.layers.Lambda(lambda cats: table.lookup(cats))(categories)\n",
        "cat_embed = keras.layers.Embedding(input_dim=6, output_dim=2)(cat_indices)\n",
        "encoded_inputs = keras.layers.concatenate([regular_inputs, cat_embed])\n",
        "outputs = keras.layers.Dense(1)(encoded_inputs)\n",
        "model = keras.models.Model(inputs=[regular_inputs, categories],\n",
        "                           outputs=[outputs])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42RopVRMbVFK"
      },
      "source": [
        "Code explanation:\n",
        "\n",
        "- (Line 6): A regular input containing 8 numerical features per instance.\n",
        "\n",
        "- (Line 7): A categorial input containing one categorical feature per instance.\n",
        "\n",
        "- (Line 8): `Lambda` layer to look up each category's index.\n",
        "\n",
        "- (Line 9): Looks up the embeddings for these indices.\n",
        "\n",
        "- (Line 10): Concatenates the embeddings and regular inputs in order to give the encoded inputs, ready to be fed to a neural network.\n",
        "\n",
        "- (Line 11): Add a dense output layer.\n",
        "\n",
        "- (Line 12): Create the Keras model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQRP9A67rrlQ"
      },
      "source": [
        "### 13.3.3 Keras Preprocessing Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQYh4ziSd2P8"
      },
      "source": [
        "To use these preprocessing layers:\n",
        "- Create the layer\n",
        "- Call its `adapt()` method with a data sample\n",
        "- Use the layer normally in the model\n",
        "\n",
        "`keras.layers.Discretization` layer will chop continuous data into different bins and encode each bin as a one-hot vector. For example, (low, medium, high) would be encoded as $[1, 0, 0], [0, 1, 0], [0, 0, 1]$.\n",
        "\n",
        "> Note: The `Discretization` layer will not be differentiable, and should only be used at the start of your model.\n",
        "\n",
        "> Note: You should not use an `Embedding` layer directly in a custom preprocessing layer. If you want it to be trainable, add it separately to your model.\n",
        "\n",
        "Use `PreprocessingStage` class to chain multiple preprocessing layers.\n",
        "\n",
        "> **NOTE**: `PreprocessingStage` class not found or may have been deprecated. Use `PreprocessingLayer` instead."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJVKE2pEfZ__"
      },
      "source": [
        "\"\"\"Create a preprocessing pipeline that will\n",
        "first normalize the inputs, then discretize them.\"\"\"\n",
        "\n",
        "# Layers in keras.layers.experimental.preprocessing\n",
        "normalization = keras.layers.experimental.preprocessing.Normalization()\n",
        "discretization = keras.layers.experimental.preprocessing.Discretization(3)\n",
        "# PreprocessingStage not found/may be deprecated, use PreprocessingLayer\n",
        "pipeline = keras.layers.experimental.preprocessing.PreprocessingLayer([normalization, discretization])\n",
        "pipeline.adapt(housing) # Use housing dataset as example for data sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk2GcVEii4Ia"
      },
      "source": [
        "`TextVectorization` layer will have an option to output word count vectors instead of word indices.\n",
        "\n",
        "For example, if vocabulary is `[\"and\", \"basketball\", \"more\"]` and text is `\"more and more\"`, text will be mapped to vector `[1, 0, 2]`: \"and\" 1x, \"basketball\" 0x, and \"more\" 2x.\n",
        "\n",
        "**Bag of words** - Word-count vector since it loses the order of the words.\n",
        "\n",
        "**Term-Frequency x Inverse-Document-Frequency** (TF-IDF) - Technique that normalizes the word counts and reduces the importance of frequent words by dividing each word count by the log of the total number of training instances in which the word appears.\n",
        "\n",
        "Continuing the example, \"and\", \"basketball\", \"more\" has 200, 10, 100 text instances in the training set. So the final vector will be $[1/\\log(200), 0/\\log(10), 2/\\log(100)] \\approx [0.19, 0., 0.43]$.\n",
        "\n",
        "> Note: You still have the option to create your own custom preprocessing layer, by subclassing `keras.layers.PreprocessingLayer` class with an `adapt()` method, which should take a `data_sample` argument and optionally an extra `reset_state` argument."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amrKe1DirrlR"
      },
      "source": [
        "## 13.4 TF Transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4rl5WQroasi"
      },
      "source": [
        "If preprocessing is computationally expensive, then handling it before training rather than on the fly may give a significant speedup: the data wil be preprocessed just once per instance **before** training, rather than once per instance and per epoch **during** training.\n",
        "\n",
        "But there's a big problem: whenever you want to change the preprocessing logic, you will need to update the Apache Beam code, mobile app code, and JavaScript code. This **training/serving skew** will lead to bugs or degraded performance.\n",
        "\n",
        "One improvement would be to take the trained model and before deploying it to your app or browser, add extra preprocessing layers to take care of preprocessing on the fly.\n",
        "\n",
        "**TF Transform** - Part of TensorFlow Extended (TFX), an end-to-end platform for productionizing TensorFlow models, and it's designed to define preprocessing operations just once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnAG6Jo4qXBr"
      },
      "source": [
        "!pip install tensorflow_transform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EcVwpoerbZR"
      },
      "source": [
        "import tensorflow_transform as tft"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klORL_IYrlvt"
      },
      "source": [
        "def preprocess(inputs): # inputs = a batch of input features\n",
        "    median_age = inputs[\"housing_mean_age\"]\n",
        "    ocean_proximity = inputs[\"ocean_proximity\"]\n",
        "    standardized_age = tft.scale_to_z_score(median_age)\n",
        "    ocean_proximity_id = tft.compute_and_apply_vocabulary(ocean_proximity)\n",
        "    return {\n",
        "        \"standardized_mean_age\": standardized_age,\n",
        "        \"ocean_proximity_id\": ocean_proximity_id\n",
        "    }"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxMIf2xzsSLx"
      },
      "source": [
        "Next, TF Transform lets you apply this `preprocess()` function to the whole training set using Apache Beam.\n",
        "\n",
        "Code Explanation: **Analyzers** that compute these.\n",
        "\n",
        "- (Line 4): The mean and standard deviation of the `housing_median_age` feature.\n",
        "\n",
        "- (Line 5): The vocabulary of the `ocean_proximity` feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxyCzpDLrrlR"
      },
      "source": [
        "## 13.5 The TensorFlow Datasets (TFDS) Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YtFkR-ktHcB"
      },
      "source": [
        "The TensorFlow Datasets project makes it very easy to download common datasets, from small ones like MNIST or Fashion MNIST to huge datasets like ImageNet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_MoRLZftkbX"
      },
      "source": [
        "# TFDS is not bundled with TensorFlow\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "766jS1Aetnh4"
      },
      "source": [
        "# Download MNIST\n",
        "dataset = tfds.load(name=\"mnist\")\n",
        "mnist_train, mnist_test = dataset[\"train\"], dataset[\"test\"]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "pqr3kUW2uIuC",
        "outputId": "b127c9c5-ff22-4527-f83d-e01bc2cffe0b"
      },
      "source": [
        "\"\"\" Apply any transformations:\n",
        "shuffling, batching, prefetching.\"\"\"\n",
        "\n",
        "plt.figure(figsize=(6,3)) # from textbook notebook\n",
        "mnist_train = mnist_train.shuffle(10000).batch(32).prefetch(1)\n",
        "for item in mnist_train:\n",
        "    images = item[\"image\"]\n",
        "    labels = item[\"label\"]\n",
        "\n",
        "    # from textbook notebook\n",
        "    # Plotting\n",
        "    for index in range(5):\n",
        "        plt.subplot(1, 5, index + 1)\n",
        "        image = images[index, ..., 0]\n",
        "        label = labels[index].numpy()\n",
        "        plt.imshow(image, cmap=\"binary\")\n",
        "        plt.title(label)\n",
        "        plt.axis(\"off\")\n",
        "    break # just showing part of the first batch"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x216 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35NzJSgmv37s"
      },
      "source": [
        "> Note: `load()` function shuffles each data shard it downloads but may not be enough. So it's best to shuffle the training set some more."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udb-1VEpv3Sw"
      },
      "source": [
        "\"\"\"Transform dataset from dictionary to tuple\n",
        "using map() method.\"\"\"\n",
        "\n",
        "mnist_train = mnist_train.shuffle(10000).batch(32)\n",
        "mnist_train = mnist_train.map(lambda items: (items[\"image\"], items[\"label\"]))\n",
        "mnist_train = mnist_train.prefetch(1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6Xxc6ZPw05J",
        "outputId": "9e334e41-0ebd-4201-cd7c-547812683bb9"
      },
      "source": [
        "\"\"\"Ask load() function to transform dataset for you\n",
        "by setting as_supervised=True.\"\"\"\n",
        "\n",
        "datasets = tfds.load(name=\"mnist\", batch_size=32, as_supervised=True)\n",
        "mnist_train = datasets[\"train\"].prefetch(1)\n",
        "model = keras.models.Sequential([\n",
        "    # from textbook notebook\n",
        "    keras.layers.Flatten(input_shape=[28, 28, 1]),\n",
        "    keras.layers.Lambda(lambda images: tf.cast(images, tf.float32)),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              # Default \"sgd\" learning rate too small\n",
        "              optimizer=keras.optimizers.SGD(lr=1e-3))\n",
        "model.fit(mnist_train, epochs=5)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 40.8128\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 25.5163\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 24.3110\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 23.6515\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 2s 1ms/step - loss: 23.4816\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ffb536975d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    }
  ]
}