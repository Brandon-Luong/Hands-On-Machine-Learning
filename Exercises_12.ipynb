{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "7b58ff03a81b7b220740b362f01ec4719380627cca970f4b363191d14b8c12ac"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Chapter 12: Custom Models and Training with TensorFlow Exercises"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1.\n",
    "\n",
    "> How would you describe TensorFlow in a short sentence?\n",
    "\n",
    "> What are its main features?\n",
    "\n",
    "> Can you name other popular Deep Learning libraries?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "TensorFlow is a powerful library for numerical computation, particularly well suited and fine-tuned for large-scale Machine Learning.\n",
    "\n",
    "Its main features are:\n",
    "- Core is very similar to NumPy, but with GPU support.\n",
    "- Supports distributed computing.\n",
    "- A just-in-time compiler that allows it to optimize computations for speed and memory usage.\n",
    "- Computation graphs can be exported to a portable format.\n",
    "- Implements autodiff and provides some excellent optimizers.\n",
    "\n",
    "Other popular Deep Learning libraries include: PyTorch, Microsoft Cognitive Toolkit (CNTK), and Theano."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2.\n",
    "\n",
    "> Is TensorFlow a drop-in replacement for NumPy?\n",
    "\n",
    "> What are the main differences between the two?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Although TensorFlow shares many similarities with NumPy it is not a drop-in replacement.\n",
    "\n",
    "- Not all functions share the same name.\n",
    "- Some TensorFlow functions create a new object whereas NumPy changes its view.\n",
    "- Tensors are immutable compared to ndarrays which are mutable."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 3.\n",
    "\n",
    "> Do you get the same result with `tf.range(10)` and `tf.constant(np.arange(10))`?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "They both return the same tensor but the numbers in `tf.range(10)` will be 32-bit while `tf.constant(np.arange(10))` will be 64-bit since NumPy uses 64-bit."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 4.\n",
    "\n",
    "> Can you name six other data structures available in TensorFlow, beyond regular tensors?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- Sparse tensors\n",
    "- Tensor arrays\n",
    "- Ragged tensors\n",
    "- String tensors\n",
    "- Sets\n",
    "- Queues"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 5.\n",
    "\n",
    "> A custom loss function can be defined by writing a function or by subclassing the `keras.losses.Loss` class.\n",
    "\n",
    "> When would you use each option?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Writing a function is the general use case for creating a custom loss function, and you should use it when the implemented loss functions such as mean squared error (MSE) or MAE (mean absolute error) do not work well in your model.\n",
    "\n",
    "Subclassing the `keras.losses.Loss` class should be used when you want to save the hyperparameter values in the custom loss function by implementing its `get_config()` method."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 6.\n",
    "\n",
    "> Similarly, a custom metric can be defined in a function or a subclass of `keras.metrics.Metric`.\n",
    "\n",
    "> When would you use each option?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Defining a custom metric in a function is the general use case since Keras automatically calls it for each batch and keeps track of the mean during each epoch.\n",
    "\n",
    "Defining a custom metric by subclassing `keras.metrics.Metric` is useful when you want to save the hyperparameter values or need to implement a streaming metric, which gradually updates batch after batch instead of an average of all batches."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 7.\n",
    "\n",
    "> When should you create a custom layer versus a custom model?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Create custom layers for the internal components of the model (ie. layers or reusable blocks of layers).\n",
    "\n",
    "Create a custom model for the model itself (ie. the object you will train)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 8.\n",
    "\n",
    "> What are some use cases that require writing your own custom training loop?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- When you want to use multiple optimizers since the `fit()` method will only use the one when originally compiled.\n",
    "- When you want more control over the code and have it explicitly written out."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 9.\n",
    "\n",
    "> Can custom Keras components contain arbitrary Python code, or must they be convertible to TF Functions?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Custom Keras components can contain arbitrary Python code since Keras automatically converts them into TF Functions."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 10.\n",
    "\n",
    "> What are the main rules to respect if you want a function to be convertible to a TF Function?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- Code from external libraries will not be included in a TensorFlow graph. The function must only include TensorFlow constructs (tensors, operations, variables, datasets, etc).\n",
    "- Other Python or TF Functions can be called but must follow the same rules.\n",
    "- TensorFlow variables must be created in the very first call or else an exception will be raised.\n",
    "- The source code of the Python function must be available to TensorFlow or else the graph generation process will fail or have limited functionality.\n",
    "- TensorFlow will only capture `for` loops that iterate over a tensor or a dataset.\n",
    "- Always use vectorized implementation if possible."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 11.\n",
    "\n",
    "> When would you need to create a dynamic Keras model?\n",
    "\n",
    "> How do you do that?\n",
    "\n",
    "> Why not make all your models dynamic?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Creating a dynamic Keras model is useful for:\n",
    "- Debugging since you can run the model in a Python debugger\n",
    "- Including arbitrary Python code that you don't want to be converted\n",
    "- Including code from external libraries like NumPy\n",
    "\n",
    "To create a dynamic Keras model, set `dynamic=True` when creating a custom layer or model or set `run_eagerly=True` when calling the model's `compile()` method.\n",
    "\n",
    "It's not a good idea to make all models dynamic because certain code will not run since it's not a TF Function and will be slower since TensorFlow will not be able to do any graph optimization on the code."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 12.\n",
    "\n",
    "> Implement a custom layer that performs *Layer Normalization*:\n",
    "\n",
    "> a. The `build()` method should define two trainable weights $\\alpha$ and $\\beta$, both of shape `input_shape[-1:]` and data type `tf.float32`. $\\alpha$ should be initialized with 1s, and $\\beta$ with 0s.\n",
    "\n",
    "> b. The `call()` method should compute the mean $\\mu$ and standard deviation $\\sigma$ of each instance's features.\n",
    "\n",
    ">> - For this, you can use `tf.nn.moments(inputs, axes=-1, keepdims=True)`, which returns the mean $\\mu$ and the variance $\\sigma^2$ of all instances (compute the square root of the variance to get the standard deviation).\n",
    "\n",
    ">> - Then the function should compute and return $\\alpha \\oplus (\\mathbf{X} - \\mu)/(\\sigma + \\epsilon) + \\beta$, where $\\oplus$ represents itemwise multiplication (*) and $\\epsilon$ is a smoothing term (small constant to avoid division by zero, eg. 0.001).\n",
    "\n",
    "> c. Ensure that your custom layer produces the same (or very nearly the same) output as the `keras.layers.LayerNormalization` layer."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 13.\n",
    "\n",
    "> Train a model using a custom training loop to tackle the Fashion MNIST dataset.\n",
    "\n",
    "> a. Display the epoch, iteration, mean training loss, and mean accuracy over each epoch (updated at each iteration), as well as the validation loss and accuracy at the end of each epoch.\n",
    "\n",
    "> b. Try using a different optimizer with a different learning rate for the upper layers and the lower layers."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}