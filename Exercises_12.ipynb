{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "7b58ff03a81b7b220740b362f01ec4719380627cca970f4b363191d14b8c12ac"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Chapter 12: Custom Models and Training with TensorFlow Exercises"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1.\n",
    "\n",
    "> How would you describe TensorFlow in a short sentence?\n",
    "\n",
    "> What are its main features?\n",
    "\n",
    "> Can you name other popular Deep Learning libraries?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2.\n",
    "\n",
    "> Is TensorFlow a drop-in replacement for NumPy?\n",
    "\n",
    "> What are the main differences between the two?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 3.\n",
    "\n",
    "> Do you get the same result with `tf.range(10)` and `tf.constant(np.arange(10))`?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 4.\n",
    "\n",
    "> Can you name six other data structures available in TensorFlow, beyond regular tensors?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 5.\n",
    "\n",
    "> A custom loss function can be defined by writing a function or by subclassing the `keras.losses.Loss` class.\n",
    "\n",
    "> When would you use each option?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 6.\n",
    "\n",
    "> Similarly, a custom metric can be defined in a function or a subclass of `keras.metrics.Metric`.\n",
    "\n",
    "> When would you use each option?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 7.\n",
    "\n",
    "> When should you create a custom layer versus a custom model?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 8.\n",
    "\n",
    "> What are some use cases that require writing your own custom training loop?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 9.\n",
    "\n",
    "> Can custom Keras components contain arbitrary Python code, or must they be convertible to TF Functions?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 10.\n",
    "\n",
    "> What are the main rules to respect if you want a function to be convertible to a TF Function?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 11.\n",
    "\n",
    "> When would you need to create a dynamic Keras model?\n",
    "\n",
    "> How do you do that?\n",
    "\n",
    "> Why not make all your models dynamic?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 12.\n",
    "\n",
    "> Implement a custom layer that performs *Layer Normalization*:\n",
    "\n",
    "> a. The `build()` method should define two trainable weights $\\alpha$ and $\\beta$, both of shape `input_shape[-1:]` and data type `tf.float32`. $\\alpha$ should be initialized with 1s, and $\\beta$ with 0s.\n",
    "\n",
    "> b. The `call()` method should compute the mean $\\mu$ and standard deviation $\\sigma$ of each instance's features.\n",
    "\n",
    ">> - For this, you can use `tf.nn.moments(inputs, axes=-1, keepdims=True)`, which returns the mean $\\mu$ and the variance $\\sigma^2$ of all instances (compute the square root of the variance to get the standard deviation).\n",
    "\n",
    ">> - Then the function should compute and return $\\alpha \\oplus (\\mathbf{X} - \\mu)/(\\sigma + \\epsilon) + \\beta$, where $\\oplus$ represents itemwise multiplication (*) and $\\epsilon$ is a smoothing term (small constant to avoid division by zero, eg. 0.001).\n",
    "\n",
    "> c. Ensure that your custom layer produces the same (or very nearly the same) output as the `keras.layers.LayerNormalization` layer."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 13.\n",
    "\n",
    "> Train a model using a custom training loop to tackle the Fashion MNIST dataset.\n",
    "\n",
    "> a. Display the epoch, iteration, mean training loss, and mean accuracy over each epoch (updated at each iteration), as well as the validation loss and accuracy at the end of each epoch.\n",
    "\n",
    "> b. Try using a different optimizer with a different learning rate for the upper layers and the lower layers."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}