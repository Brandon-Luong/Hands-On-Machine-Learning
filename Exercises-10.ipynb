{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "7b58ff03a81b7b220740b362f01ec4719380627cca970f4b363191d14b8c12ac"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Chapter 10: Introduction to Artificial Neural Networks with Keras Exercises"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1.\n",
    "\n",
    "> The TensorFlow Playground is a handy neural network simulator built by the TensorFlow team. \n",
    "\n",
    "> In this exercise, you will train several binary classifiers in just a few clicks, and tweak the model's architecture and its hyperparameters to gain some intuition on how neural networks work and what their hyperparameters do. Take some time to explore the following:\n",
    "\n",
    ">> a. The patterns learned by a neural net.\n",
    ">>\n",
    ">>> - Try training the default neural network by clicking the Run button (top left).\n",
    ">>>\n",
    ">>> - Notice how it quickly finds a good solution for the classification task.\n",
    ">>>\n",
    ">>> - The neurons in the first hidden layer have learned simple patterns, while the neurons in the second hidden layer have learned to combine the simple patterns of the first hidden layer into more complex patterns.\n",
    ">>>\n",
    ">>> - In general, the more layers there are, the more complex the patterns can be.\n",
    ">>\n",
    ">> b. Activation functions.\n",
    ">>\n",
    ">>> - Try replacing the tanh activation function with a ReLU activation function, and train the network again.\n",
    ">>>\n",
    ">>> - Notice that it finds a solution even faster, but this time the boundaries are linear. This is due to the shape of the ReLU function.\n",
    ">>\n",
    ">> c. The risk of local minima.\n",
    ">>\n",
    ">>> - Modify the network architecture to have just one hidden layer with three neurons.\n",
    ">>>\n",
    ">>> - Train it multiple times (to reset the network weights, click the Reset button next to the Play button).\n",
    ">>>\n",
    ">>> - Notice that the training time varies a lot, and sometimes it even gets stuck in a local minimum.\n",
    ">>\n",
    ">> d. What happens when neural nets are too small.\n",
    ">>\n",
    ">>> - Remove one neuron to keep just two.\n",
    ">>>\n",
    ">>> - Notice that the neural network is now incapable of finding a good solution, even if you try multiple times.\n",
    ">>>\n",
    ">>> - The model has too few parameters and systematically underfits the training set.\n",
    ">>\n",
    ">> e. What happens when neural nets are large enough.\n",
    ">>\n",
    ">>> - Set the number of neurons to eight, and train the network several times.\n",
    ">>>\n",
    ">>> - Notice that it is now consistently fast and never gets stuck.\n",
    ">>>\n",
    ">>> - This highlights an important finding in neural network theory: large neural networks almost never get stuck in local minima, and even when they do these local optima are almost as good as the global optimum.\n",
    ">>>\n",
    ">>> - However, they can still get stuck on long plateaus for a long time.\n",
    ">>\n",
    ">> f. The risk of vanishing gradients in deep networks.\n",
    ">>\n",
    ">>> - Select the spiral dataset (the bottom-right dataset under \"DATA\"), and change the network architecture to have four hidden layers with eight neurons each.\n",
    ">>>\n",
    ">>> - Notice that training takes much longer and often gets stuck on plateaus for long periods of time.\n",
    ">>>\n",
    ">>> - Also notice that the neurons in the highest layers (on the right) tend to evolve faster than the neurons in the lowest layers (on the left).\n",
    ">>>\n",
    ">>> - This problem, called the \"vanishing gradients\" problem, can be alleviated with better weight initialization and other techniques, better optimizers (such as AdaGrad or Adam), or Batch Normalization (discussed in Chapter 11).\n",
    ">>\n",
    ">> g. Go further.\n",
    ">>\n",
    ">>> - Take an hour or so to play around with other parameters and get a feel for what they do, to build an intuitive understand about neural networks."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "a.\n",
    "- I can see that for the 1st hidden layer, the patterns learned are linear decision boundaries.\n",
    "- For the 2nd hidden layer, the decision boundaries are more complicated.\n",
    "\n",
    "b.\n",
    "- Switching to ReLU, I can see that it converges much faster than tanh (lower number of epochs).\n",
    "- The boundaries are straight lines (a hexagon decision boundary) compared to tanh's circular decision boundary.\n",
    "\n",
    "c.\n",
    "- I noticed that ReLU tended to get stuck on a local minimum much more than using tanh.\n",
    "- When using tanh, it would get stuck on a local minimum for a little bit but eventually converge correctly.\n",
    "\n",
    "d.\n",
    "- I see that by decreasing the number of neurons to just 2, the neural network fails to find a good decision boundary (with test loss at about 0.24 vs. 0.005).\n",
    "- It is underfitting the training set.\n",
    "\n",
    "e.\n",
    "- With 8 neurons, the neural network never gets stuck at a local optimum and always converges.\n",
    "\n",
    "f.\n",
    "- With 4 hidden layers of 8 neurons each, training takes a significantly longer time.\n",
    "- I also see that it tends to get stuck on plateaus a lot more often.\n",
    "\n",
    "g.\n",
    "- I can see how the too large of a learning rate can cause the neural network to diverge.\n",
    "- And too small of a learning rate takes it forever to converge.\n",
    "- Despite having many layers (6), the neural network can still fail to converge if there's just not enough neurons (1 per layer)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2.\n",
    "\n",
    "> - Draw an ANN using the original artificial neurons (like the ones in Figure 10-3 \"logic operations\") that computes $ A \\oplus B $ (where $\\oplus$ represents the XOR operation).\n",
    "\n",
    ">> Hint: $ A \\oplus B = (A \\wedge \\neg B \\lor (\\neg A \\wedge B)$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "See attached picture."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 3.\n",
    "\n",
    "> - Why is it generally preferable to use a Logistic Regression classifier rather than a classical Perceptron (ie. a single layer of threshold logic units trained using the Perceptron training algorithm)?\n",
    "\n",
    "> - How can you tweak a Perceptron to make it equivalent to a Logistic Regression classifier?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Perceptrons do not output a class probability; they make predictions based on a hard threshold (0 or 1). So it's generally preferable to use Logistic Regression classifier.\n",
    "\n",
    "To make it equivalent to a Logistic Regression classifier, change the step function to the logistic activation function, so that the output will then be between 0-1, a probability of the positive class."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 4.\n",
    "\n",
    "> - Why was the logistic activation function a key ingredient in training the first MLPs?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The logistic activation function was a key ingredient because it has a well-defined nonzero derivative everywhere, allowing Gradient Descent to make some progress at every step.\n",
    "\n",
    "The step function only contains flat segments, so there is no gradient to work with."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 5.\n",
    "\n",
    "> - Name three popular activation functions.\n",
    "\n",
    "> - Can you draw them?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The three popular activation functions are:\n",
    "- The logistic (sigmoid) function, $ \\sigma(z) = 1 / (1 + \\text{exp}(-z))$\n",
    "- The hyperbolic tangent function: $ \\tanh(z) = 2\\sigma (2z) - 1 $\n",
    "- The Rectified Linear Unit funtion: $\\text{ReLU}(z) = \\max(0, z)$\n",
    "\n",
    "See attached picture."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 6.\n",
    "\n",
    "> Suppose you have an MLP composed of one input layer with 10 passthrough neurons, followed by one hidden layer with 50 artificial neurons, and finally one output layer with 3 artificial neurons. All artificial neurons use the ReLU activation function.\n",
    "\n",
    "> - What is the shape of the input matrix $\\mathbf{X}$?\n",
    "\n",
    "> - What are the shapes of the hidden layer's weight vector $\\mathbf{W}_h$ and its bias vector $\\mathbf{b}_h$?\n",
    "\n",
    "> - What are the shapes of the output layer's weight vector $\\mathbf{W}_o$ and its bias vector $\\mathbf{b}_o$?\n",
    "\n",
    "> - What is the shape of the network's output matrix $\\mathbf{Y}$?\n",
    "\n",
    "> - Write the equation that computes the network's output matrix $\\mathbf{Y}$ as a function of $\\mathbf{X}$, $\\mathbf{W}_h$, $\\mathbf{b}_h$, $\\mathbf{W}_o$, and $\\mathbf{b}_o$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\\# of input neurons = 1 per input feature.\n",
    "\n",
    "The hidden layer's weight vector $\\mathbf{W}_h$ has 1 row per input neuron and 1 column per artificial neuron.\n",
    "\n",
    "The hidden layer's bias vector $\\mathbf{b}_h$ has 1 bias term per artificial neuron.\n",
    "\n",
    "- The shape of $\\mathbf{X} = (m \\times 10) $, where $m$ is the number of instances.\n",
    "- The shape of $\\mathbf{W}_h = (10 \\times 50)$.\n",
    "- The shape of $\\mathbf{b}_h = (50 \\times 1)$.\n",
    "- The shape of $\\mathbf{W}_o = (10 \\times 3)$.\n",
    "- The shape of $\\mathbf{b}_o = 0$. There is no bias term in output layer.\n",
    "- The shape of $\\mathbf{Y} = (m \\times 3)$.\n",
    "- $ \\mathbf{Y} = \\text{ReLU}(\\text{ReLU}(\\mathbf{X}\\mathbf{W}_h + \\mathbf{b}_h) \\mathbf{W}_o + \\mathbf{b}_o)$."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 7.\n",
    "\n",
    "> - How many neurons do you need in the output layer if you want to classify email into spam or ham?\n",
    "\n",
    "> - What activation function should you use in the output layer?\n",
    "\n",
    "> - If instead you want to tackle MNIST, how many neurons do you need in the output layer?\n",
    "\n",
    "> - Which activation function should you use?\n",
    "\n",
    "> - What about for getting your network to predict housing prices, as in Chapter 2?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "You only need 1 neuron in output layer to classify spam or ham (binary classification).\n",
    "\n",
    "You should use the logistic activation function in the output layer.\n",
    "\n",
    "You would need 10 neurons in output layer to tackle MNIST (1 per class).\n",
    "\n",
    "You should use the softmax activation function (probabilities between 0-1, all add up to 1 since classes are exclusive).\n",
    "\n",
    "For predicting housing prices, you only need 1 neuron in output layer (predict single value) and do not use any activation function (free to output any range of values)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 8.\n",
    "\n",
    "> - What is backpropagation and how does it work?\n",
    "\n",
    "> - What is the difference between backpropagation and reverse-mode autodiff?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Backpropagation is Gradient Descent that uses an efficient technique to compute the gradients automatically. It computes the error gradients from each connection in the layer below (starting from output layer and moving backward until input layer) using the chain rule of calculus and then performs a step of Gradient Descent to iteratively converge.\n",
    "\n",
    "Backpropagation and reverse-mode autodiff is kind of the same process, except that reverse-mode autodiff takes into account the feed forward process of the neural network, whereas backpropagation is only the backward process.\n",
    "\n",
    "Backpropagation (back).  \n",
    "Reverse-mode autodiff (forward & back)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 9.\n",
    "\n",
    "> - Can you list all the hyperparameters you can tweak in a basic MLP?\n",
    "\n",
    "> - If the MLP overfits the training data, how could you tweak these hyperparameters to try to solve the problem?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The hyperparameters you can tweak in a basic MLP are:\n",
    "- Number of layers\n",
    "- Number of neurons per layer\n",
    "- Learning rate\n",
    "- Optimizer\n",
    "- Batch size\n",
    "- Activation function\n",
    "- Number of iterations\n",
    "\n",
    "If the MLP overfits the training data,\n",
    "- Decrease the number of layers\n",
    "- Decrease the number of neurons per layer\n",
    "- Alternatively, use a large number of layers and neurons but use early stopping to prevent it from overfitting\n",
    "- Start with a slow learning rate and gradually increase it by a constant factor. Then plot the loss vs learning rate and pick the learning rate right before the loss starts to increase again (meaning it's starting to overfit).\n",
    "- Tune the hyperparameters of the optimizer.\n",
    "- Start with a large batch size using learning rate warmup, and if it overfits, decrease the batch size.\n",
    "- Change the activation function depending on what kind of output you want, but ReLU is a good default use.\n",
    "- Use early stopping instead of tweaking the number of iterations."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 10.\n",
    "\n",
    "> 1. Train a deep MLP on the MNIST dataset.\n",
    "\n",
    ">> You can load it using `keras.datasets.mnist.load_data()`.\n",
    "\n",
    "> 2. See if you can get over 98% precision.\n",
    "\n",
    "> 3. Try searching for the optimal learning rate by using the approach presented in this chapter.\n",
    "\n",
    ">> ie. by growing the learning rate exponentially, plotting the loss, and finding the point where the loss shoots up.\n",
    "\n",
    "> 4. Try adding all the bells and whistles - save checkpoints, use early stopping, and plot learning curves using TensorBoard."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}