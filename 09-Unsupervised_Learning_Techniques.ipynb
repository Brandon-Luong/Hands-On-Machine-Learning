{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "7b58ff03a81b7b220740b362f01ec4719380627cca970f4b363191d14b8c12ac"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Chapter 9: Unsupervised Learning Techniques"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import numpy as np"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 12,
   "outputs": []
  },
  {
   "source": [
    "- **Clustering**:\n",
    "    - Group similar instances together into *clusters*.\n",
    "\n",
    "- **Anomoly detection**:\n",
    "    - Learn what \"normal\" data looks like, and then use that to detect abnormal instances.\n",
    "\n",
    "- **Density estimation**:\n",
    "    - Estimating the *probability density function (PDF)* of the random process that generated the dataset."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 9.1 Clustering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Clustering** - The task of identifying similar instances and assigning them to *clusters*, or groups of similar instances.\n",
    "\n",
    "Various applications of clustering:\n",
    "- Customer segmentation\n",
    "    - Cluster your customers based on their purchases and their activity on your website.\n",
    "    - Understand who your customers are and their needs so you can adapt your products and marketing to each segment.\n",
    "    - Useful in *recommender systems* to suggest content that others in the same cluster enjoyed.\n",
    "    \n",
    "- Data analysis\n",
    "    - When you analyze a new dataset, it can be helpful to run a clustering algorithm, and then analyze each cluster separately.\n",
    "\n",
    "- Dimensionality reduction technique\n",
    "    - Once a dataset has been clustered, it's possible to measure each instance's affinity with each cluster.\n",
    "    - **Affinity** is any measure of how well an instance fits into a cluster.\n",
    "    - Each instance's feature vector can then be replaced with the vector of its cluster affinities.\n",
    "    - If there are *k* clusters, then the vector will be *k*-dimensional.\n",
    "    - The vector is typically much lower-dimensional than the original feature vector, but preserves enough information for further processing.\n",
    "\n",
    "- Anomaly detection (also called outlier detection)\n",
    "    - Any instance that has a low affinity to all the clusters is likely to be an anomaly.\n",
    "    - Detect unusual behavior such as unusual number of request per second.\n",
    "    - Particularly useful in detecting defects in manufactoring or fraud detection.\n",
    "\n",
    "- Semi-supervised learning\n",
    "    - If you only have a few labels, you can propagate the labels to all the instances in the same cluster.\n",
    "    - Greatly improves the number of labels available for subsequent supervised learning algorithms, improving performance.\n",
    "\n",
    "- Search engines\n",
    "    - Some search engines let you search for images that are similar to a reference image.\n",
    "    - Perform clustering and then return all the images from the same cluster.\n",
    "\n",
    "- Segment an image\n",
    "    - By clustering pixels according to their color and replacing each pixel's color with the mean color of its cluster, it's possible to reduce the number of different colors in the image.\n",
    "    - Used in object detection and tracking systems.\n",
    "    - Makes it easier to detect the contour of each object."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 9.1.1 K-Means"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The K-Means algorithm is a simple algorithm capable of clustering clearly defined \"blobs\" of instances.\n",
    "\n",
    "> Note: See Figure 9-2 in book."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM BOOK NOTEBOOK\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "blob_centers = np.array(\n",
    "    [[ 0.2,  2.3],\n",
    "     [-1.5 ,  2.3],\n",
    "     [-2.8,  1.8],\n",
    "     [-2.8,  2.8],\n",
    "     [-2.8,  1.3]])\n",
    "blob_std = np.array([0.4, 0.3, 0.1, 0.1, 0.1])\n",
    "X, y = make_blobs(n_samples=2000, centers=blob_centers,\n",
    "                  cluster_std=blob_std, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "kmeans= KMeans(n_clusters=k)\n",
    "y_pred = kmeans.fit_predict(X)"
   ]
  },
  {
   "source": [
    "> Note: You have to specify the number of clusters *k* that the algorithm must find.\n",
    "\n",
    "In context of clustering, an instance's *\"label\"* is the index of the cluster that this instance gets assigned to."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([4, 0, 1, ..., 3, 1, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "y_pred is kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-2.80389616,  1.80117999],\n",
       "       [ 0.20876306,  2.25551336],\n",
       "       [-1.46679593,  2.28585348],\n",
       "       [-2.79290307,  2.79641063],\n",
       "       [-2.80037642,  1.30082566]])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "source": [
    "You can easily assign new instances to the cluster whose centroid is closest."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 1, 3, 3])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "X_new = np.array([[0, 2], [3, 2], [-3, 3], [-3, 2.5]])\n",
    "kmeans.predict(X_new)"
   ]
  },
  {
   "source": [
    "> Note: K-Means algorithm does not behave very well when the blobs have very different diameters because all it cares about when assigning an instance to a cluster is the distance to the centroid.\n",
    "\n",
    "*Hard clustering* - Assigning each instance to a single cluster.  \n",
    "*Soft clustering* - Give each instance a score per cluster.\n",
    "\n",
    "In the `KMeans` class, `transform()` measures the distance from each instance to every centroid."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[2.81093633, 0.32995317, 1.49439034, 2.9042344 , 2.88633901],\n",
       "       [5.80730058, 2.80290755, 4.4759332 , 5.84739223, 5.84236351],\n",
       "       [1.21475352, 3.29399768, 1.69136631, 0.29040966, 1.71086031],\n",
       "       [0.72581411, 3.21806371, 1.54808703, 0.36159148, 1.21567622]])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "kmeans.transform(X_new)"
   ]
  },
  {
   "source": [
    "First instance in `X_new` is located at a distance of:\n",
    "- 2.81 from the 1st centroid\n",
    "- 0.33 from the 2nd centroid\n",
    "- 2.90 from the 3rd centroid\n",
    "- 1.49 from the 4th centroid\n",
    "- 2.89 from the 5th centroid\n",
    "\n",
    "Transforming into a k-dimensional dataset can be a very efficient nonlinear dimensionality reduction technique."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 9.1.1.1 The K-Means algorithm"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "How does the algorithm work?\n",
    "\n",
    "1. Start by placing the centroids randomly (eg. pick *k* instances at random and use their locations as centroids).\n",
    "2. Label the instances.\n",
    "3. Update the centroids.\n",
    "4. Repeat steps 2 & 3 until centroids stop moving.\n",
    "\n",
    "> Note: The algorithm is guaranteed to converge in a finite number of steps because the mean squared distance between the instances and their closest centroid can only go down at each step. It does not oscillate forever.\n",
    "\n",
    "> Note: The computational complexity is generally linear with regard to number of instances *m*, number of clusters *k*, and number of dimensions *n*. Worst case is exponential with number of instances. But in practice, K-Means is generally one of the fastest *clustering* algorithms.\n",
    "\n",
    "Although it is guaranteed to converge, it may not converge to the right solution (eg. may converge to a local optimum). Whether it does or not depends on the centroid initialization."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 9.1.1.2 Centroid initialization methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "If you happen to know approximately where the centroids should be, you can set the `init` hyperparamter to a NumPy array containing the list of centroids and set `n_init=1`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_init = np.array([[-3, 3], [-3, 2], [-3, 1], [-1, 2], [0, 2]])\n",
    "kmeans = KMeans(n_clusters=5, init=good_init, n_init=1)"
   ]
  },
  {
   "source": [
    "Another solution is to run the algorithm multiple times with different random initializations and keep the best solution. The number of random initializations is controlled by `n_init` hyperparameter (default `=10`).\n",
    "\n",
    "It uses a performance metric called the model's **inertia**, the mean squared distance between each instance and its closest centroid."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "211.59853725816828"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "k = 5\n",
    "kmeans= KMeans(n_clusters=k)\n",
    "y_pred = kmeans.fit_predict(X)\n",
    "\n",
    "kmeans.inertia_ # Used 1st example of kmeans, Figure 9-3 in book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-211.5985372581683"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "kmeans.score(X)"
   ]
  },
  {
   "source": [
    "> Note: Negative because Scikit-Learn's \"greater is better\" rule:  \n",
    "if a predictor is better than another, its `score()` method should return a greater score.\n",
    "\n",
    "K-Means++ algorithm uses initialization step that tends to select centroids that are distant from one another.\n",
    "\n",
    "1. Take one centroid $\\mathbf{c}^{(1)}$, chosen uniformly at random from the dataset.\n",
    "2. Take a new centroid $\\mathbf{c}^{(i)}$, choosing an instance $\\mathbf{x}^{(i)}$ with probability $ D(\\mathbf{x}^{(i)})^2 / \\sum_{j=1}^{m} D(\\mathbf{x}^{(j)})^2$, where $ D(\\mathbf{x}^{(i)})$ is the distance between the instance and closest centroid that was already chosen.  \n",
    "This probability distribution ensures that instances farther away from already chosen centroids are much more likely to be selected as centroids.\n",
    "3. Repeat the previous step until all k centroids have been chosen.\n",
    "\n",
    "`KMeans` uses this method by default."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 9.1.1.3 Accelerated K-Means and mini-batch K-Means"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Accelerated K-Means by avoiding many unnecessary distance calculations. It can be achieved by exploiting the triangle inequality (ie. a straight line is always the shortest distance between two points) and by keeping track of lower and upper bounds for distances between instances and centroids.\n",
    "\n",
    "`KMeans` uses this method by default.\n",
    "\n",
    "Mini-batch K-Means uses mini-batches, moving the centroids just slightly at each iteration, instead of using the full dataset at each iteration."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "MiniBatchKMeans(n_clusters=5)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "minibatch_kmeans = MiniBatchKMeans(n_clusters=5)\n",
    "minibatch_kmeans.fit(X)"
   ]
  },
  {
   "source": [
    "> Note: Mini-batch K-Means algorithm trains much faster than regular K-Means algorithm, but its inertia is generally slightly worse, especially as the number of clusters increases. See Figure 9-6 in book."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 9.1.1.4 Finding the optimal number of clusters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The inertia is not a good performance metric when trying to choose *k* because it keeps getting lower as we increase *k*.\n",
    "\n",
    "By plotting the inertia as a function of *k*, there is an \"elbow\" at k = 4, splitting the rapid drop and the slower decrease. So it would be an okay guess to pick 4 centroids, but isn't very precise.\n",
    "\n",
    "> Note: See Figure 9-8 in book.\n",
    "\n",
    "A more precise approach is to use the **silhouette score**, which is the mean *silhouette coefficient* (between -1 and +1) over all the instances. A coefficient:\n",
    "- Close to +1 => Instance is well inside its own cluster and far from others.\n",
    "- Close to 0 => Instance is close to a cluster boundary.\n",
    "- Close to -1 => Instance may have been assigned to the wrong cluster."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.655517642572828"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "silhouette_score(X, kmeans.labels_)"
   ]
  },
  {
   "source": [
    "By plotting silhouette scores for different numbers of clusters, it provides much more information than the inertia plot. k = 4 is a very good choice, and k = 5 is good too - much better than k = 6 or 7.\n",
    "\n",
    "An even better visualization called a **silhouette diagram** is a plot of every instance's silhouette coefficient, sorted by the cluster they are assigned to and by the value of the coefficient.\n",
    "\n",
    "The dashed line indicates the mean silhouette coefficient. We want most instances to be to the right as if it falls to the left, it means they are too close to other clusters. When k = 3 and k = 6, we get bad clusters. \n",
    "\n",
    "When k = 4, the cluster at index 1 is fairly big, so picking k = 5 may be a better idea to get clusters of similar sizes.\n",
    "\n",
    "> Note: See Figure 9-10 in book."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 9.1.2 Limits of K-Means"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "As mentioned already, K-Means isn't perfect.\n",
    "\n",
    "- Needs to run several times to avoid suboptimal solution\n",
    "- Need to specify number of clusters\n",
    "- Does not perform well on clusters of varying sizes, densities, or nonspherical shapes\n",
    "\n",
    "> Note: It is important to scale the input features before running K-Means, or the clusters may be very stretched and K-Means will perform poorly."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 9.1.3 Using Clustering for Image Segmentation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Image segmentation** - The task of partitioning an image into multiple segments.  \n",
    "\n",
    "**Semantic segmentation** - All pixels that are part of the same object type get assigned to the same segment. (eg. 1 segment for all pedestrians)  \n",
    "\n",
    "**Instance segmentation** - All pixels that are part of the same individual object are assigned to the same segment. (eg. different segment for each pedestrian)\n",
    "\n",
    "**Color segmentation** - All pixels that have a similar color are assigned to the same segment."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.image import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(533, 800, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "image = imread(\"Images/Unsupervised_learning/ladybug.png\")\n",
    "image.shape"
   ]
  },
  {
   "source": [
    "The image is represented as a 3D array.\n",
    "- 1st dimension's size = Height\n",
    "- 2nd dimension's size = Width\n",
    "- 3rd dimension's size = Number of color channels (RGB)\n",
    "\n",
    "=> For each pixel, there is a 3D vector containing the intensities of red, green, and blue, each between 0.0 and 1.0."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = image.reshape(-1, 3) # Reshape array to long list of RBG colors\n",
    "kmeans = KMeans(n_clusters=8).fit(X) # Clusters these colors using K-Means\n",
    "segmented_img = kmeans.cluster_centers_[kmeans.labels_]\n",
    "segmented_img = segmented_img.reshape(image.shape)"
   ]
  },
  {
   "source": [
    "K-Means prefers clusters of similar sizes. The ladybug is small - much smaller than the rest of the image - so even though its color is flashy, K-Means fails to dedicate a cluster to it.\n",
    "\n",
    "> Note: See Figure 9-12 in book for ladybug reference."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 9.1.4 Using Clustering for Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Clustering can be an efficient approach to dimensionality reduction."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9688888888888889"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "X_digits, y_digits = load_digits(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_digits, y_digits)\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "log_reg.score(X_test, y_test)"
   ]
  },
  {
   "source": [
    "Now try using K-means as a preprocessing step. Create a pipeline that will first cluster the training set into 50 clusters and replace the images with their distances to these 50 clusters, then apply Logisitic Regression model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('kmeans', KMeans(n_clusters=50)),\n",
       "                ('log_reg', LogisticRegression())])"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"kmeans\", KMeans(n_clusters=50)),\n",
    "    (\"log_reg\", LogisticRegression())\n",
    "])\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "source": [
    "> Note: Since there are 10 different digits, it's tempting to set the number of clusters to 10. However, each digit can be written several different ways, so it is preferable to use a larger number of clusters, such as 50."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9622222222222222"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "source": [
    "Since K-Means is used as a preprocessing step before classification, it's easy to find the best value of *k* by using `GridSearchCV`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "D ..............................kmeans__n_clusters=17; total time=   0.2s\n",
      "[CV] END ..............................kmeans__n_clusters=18; total time=   0.2s\n",
      "[CV] END ..............................kmeans__n_clusters=18; total time=   0.2s\n",
      "[CV] END ..............................kmeans__n_clusters=18; total time=   0.3s\n",
      "[CV] END ..............................kmeans__n_clusters=19; total time=   0.2s\n",
      "[CV] END ..............................kmeans__n_clusters=19; total time=   0.3s\n",
      "[CV] END ..............................kmeans__n_clusters=19; total time=   0.2s\n",
      "[CV] END ..............................kmeans__n_clusters=20; total time=   0.2s\n",
      "[CV] END ..............................kmeans__n_clusters=20; total time=   0.2s\n",
      "[CV] END ..............................kmeans__n_clusters=20; total time=   0.3s\n",
      "[CV] END ..............................kmeans__n_clusters=21; total time=   0.3s\n",
      "[CV] END ..............................kmeans__n_clusters=21; total time=   0.3s\n",
      "[CV] END ..............................kmeans__n_clusters=21; total time=   0.3s\n",
      "[CV] END ..............................kmeans__n_clusters=22; total time=   0.3s\n",
      "[CV] END ..............................kmeans__n_clusters=22; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=22; total time=   0.3s\n",
      "[CV] END ..............................kmeans__n_clusters=23; total time=   0.3s\n",
      "[CV] END ..............................kmeans__n_clusters=23; total time=   0.3s\n",
      "[CV] END ..............................kmeans__n_clusters=23; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=24; total time=   0.3s\n",
      "[CV] END ..............................kmeans__n_clusters=24; total time=   0.3s\n",
      "[CV] END ..............................kmeans__n_clusters=24; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=25; total time=   0.3s\n",
      "[CV] END ..............................kmeans__n_clusters=25; total time=   0.3s\n",
      "[CV] END ..............................kmeans__n_clusters=25; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=26; total time=   0.3s\n",
      "[CV] END ..............................kmeans__n_clusters=26; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=26; total time=   0.3s\n",
      "[CV] END ..............................kmeans__n_clusters=27; total time=   0.3s\n",
      "[CV] END ..............................kmeans__n_clusters=27; total time=   0.3s\n",
      "[CV] END ..............................kmeans__n_clusters=27; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=28; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=28; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=28; total time=   0.3s\n",
      "[CV] END ..............................kmeans__n_clusters=29; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=29; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=29; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=30; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=30; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=30; total time=   0.3s\n",
      "[CV] END ..............................kmeans__n_clusters=31; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=31; total time=   0.3s\n",
      "[CV] END ..............................kmeans__n_clusters=31; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=32; total time=   0.3s\n",
      "[CV] END ..............................kmeans__n_clusters=32; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=32; total time=   0.3s\n",
      "[CV] END ..............................kmeans__n_clusters=33; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=33; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=33; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=34; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=34; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=34; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=35; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=35; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=35; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=36; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=36; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=36; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=37; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=37; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=37; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=38; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=38; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=38; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=39; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=39; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=39; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=40; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=40; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=40; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=41; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=41; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=41; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=42; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=42; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=42; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=43; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=43; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=43; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=44; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=44; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=44; total time=   0.4s\n",
      "[CV] END ..............................kmeans__n_clusters=45; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=45; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=45; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=46; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=46; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=46; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=47; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=47; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=47; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=48; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=48; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=48; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=49; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=49; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=49; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=50; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=50; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=50; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=51; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=51; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=51; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=52; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=52; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=52; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=53; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=53; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=53; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=54; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=54; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=54; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=55; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=55; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=55; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=56; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=56; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=56; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=57; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=57; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=57; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=58; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=58; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=58; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=59; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=59; total time=   0.5s\n",
      "[CV] END ..............................kmeans__n_clusters=59; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=60; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=60; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=60; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=61; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=61; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=61; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=62; total time=   0.9s\n",
      "[CV] END ..............................kmeans__n_clusters=62; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=62; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=63; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=63; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=63; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=64; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=64; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=64; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=65; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=65; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=65; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=66; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=66; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=66; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=67; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=67; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=67; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=68; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=68; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=68; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=69; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=69; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=69; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=70; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=70; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=70; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=71; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=71; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=71; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=72; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=72; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=72; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=73; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=73; total time=   0.9s\n",
      "[CV] END ..............................kmeans__n_clusters=73; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=74; total time=   0.9s\n",
      "[CV] END ..............................kmeans__n_clusters=74; total time=   0.9s\n",
      "[CV] END ..............................kmeans__n_clusters=74; total time=   1.1s\n",
      "[CV] END ..............................kmeans__n_clusters=75; total time=   1.0s\n",
      "[CV] END ..............................kmeans__n_clusters=75; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=75; total time=   1.0s\n",
      "[CV] END ..............................kmeans__n_clusters=76; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=76; total time=   1.0s\n",
      "[CV] END ..............................kmeans__n_clusters=76; total time=   0.9s\n",
      "[CV] END ..............................kmeans__n_clusters=77; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=77; total time=   0.9s\n",
      "[CV] END ..............................kmeans__n_clusters=77; total time=   1.0s\n",
      "[CV] END ..............................kmeans__n_clusters=78; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=78; total time=   0.9s\n",
      "[CV] END ..............................kmeans__n_clusters=78; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=79; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=79; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=79; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=80; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=80; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=80; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=81; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=81; total time=   0.9s\n",
      "[CV] END ..............................kmeans__n_clusters=81; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=82; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=82; total time=   0.9s\n",
      "[CV] END ..............................kmeans__n_clusters=82; total time=   0.9s\n",
      "[CV] END ..............................kmeans__n_clusters=83; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=83; total time=   1.0s\n",
      "[CV] END ..............................kmeans__n_clusters=83; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=84; total time=   1.0s\n",
      "[CV] END ..............................kmeans__n_clusters=84; total time=   0.9s\n",
      "[CV] END ..............................kmeans__n_clusters=84; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=85; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=85; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=85; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=86; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=86; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=86; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=87; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=87; total time=   0.9s\n",
      "[CV] END ..............................kmeans__n_clusters=87; total time=   0.9s\n",
      "[CV] END ..............................kmeans__n_clusters=88; total time=   0.9s\n",
      "[CV] END ..............................kmeans__n_clusters=88; total time=   1.1s\n",
      "[CV] END ..............................kmeans__n_clusters=88; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=89; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=89; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=89; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=90; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=90; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=90; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=91; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=91; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=91; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=92; total time=   0.6s\n",
      "[CV] END ..............................kmeans__n_clusters=92; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=92; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=93; total time=   1.0s\n",
      "[CV] END ..............................kmeans__n_clusters=93; total time=   1.0s\n",
      "[CV] END ..............................kmeans__n_clusters=93; total time=   1.3s\n",
      "[CV] END ..............................kmeans__n_clusters=94; total time=   0.9s\n",
      "[CV] END ..............................kmeans__n_clusters=94; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=94; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=95; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=95; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=95; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=96; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=96; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=96; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=97; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=97; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=97; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=98; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=98; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=98; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=99; total time=   0.7s\n",
      "[CV] END ..............................kmeans__n_clusters=99; total time=   0.8s\n",
      "[CV] END ..............................kmeans__n_clusters=99; total time=   0.7s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'kmeans__n_clusters': 97}"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "param_grid = dict(kmeans__n_clusters=range(2, 100))\n",
    "grid_clf = GridSearchCV(pipeline, param_grid, cv=3, verbose=2)\n",
    "grid_clf.fit(X_train, y_train)\n",
    "\n",
    "grid_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9644444444444444"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "grid_clf.score(X_test, y_test)"
   ]
  },
  {
   "source": [
    "### 9.1.5 Using Clustering for Semi-Supervised Learning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 9.1.6 DBSCAN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 9.1.7 Other Clustering Algorithms"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 9.2 Gaussian Mixtures"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 9.2.1 Anomaly Detection Using Gaussian Mixtures"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 9.2.2 Selecting the Number of Clusters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 9.2.3 Bayesian Gaussian Mixture Models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 9.2.4 Other Algorithms for Anomaly and Novelty Detection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}