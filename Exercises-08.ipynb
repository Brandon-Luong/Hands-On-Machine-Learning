{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "7b58ff03a81b7b220740b362f01ec4719380627cca970f4b363191d14b8c12ac"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Chapter 8: Dimensionality Reduction Exercises"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1.\n",
    "\n",
    "> What are the main motivations for reducing a dataset's dimensionality?\n",
    "\n",
    "> What are the main drawbacks?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The main motivations for reducing a dataset's dimensionality are: \n",
    "\n",
    "- Speeding up training\n",
    "- Data visualization\n",
    "\n",
    "With thousands or millions of features, training becomes extremely slow and finding a good solution becomes more difficult. Also when a dataset is reduced to 2 or 3 dimensions, it can be plotted to allow for the possibility deeper insight that might have been missed or to be used as a communication tool for others.\n",
    "\n",
    "The main drawbacks are:\n",
    "\n",
    "- Loss of information\n",
    "- Does not remove noise, only speeds up training\n",
    "- Pipeline becomes more complex and harder to maintain\n",
    "\n",
    "Dimensionality reduction is akin to compressing an image file. It makes the algorithm run faster but at a cost of performing worse (looking worse, in the case of image file). Also, reducing dimensions does not necessarily remove unwanted noise."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2.\n",
    "\n",
    "> What is the curse of dimensionality?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The curse of dimensionality states that high-dimensional datasets are prone to be very sparse and have a greater risk of overfitting. This is because at higher dimensions, there is just a lot of space and so instances are likely to be far apart from each other.\n",
    "\n",
    "Recall the Average distance in N-Dimension Comparison:\n",
    "\n",
    "- 2D (unit square): 0.52\n",
    "- 3D (unit cube): 0.66\n",
    "- 1,000,000-D (unit hypercube): 408.25"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 3.\n",
    "\n",
    "> Once a dataset's dimensionality has been reduced, is it possible to reverse the operation?\n",
    "\n",
    "> If so, how? If not, why?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Once a dataset's dimensionality has been reduced, it is possible to reverse the operation by computing the inverse transformation - take the projected data and matrix multiply by the principal components of the original d-dimensions.\n",
    "\n",
    "$$ \\mathbf{X}_{recovered} = \\mathbf{X}_{d-proj} \\mathbf{W}_d^T $$\n",
    "\n",
    "where $\\mathbf{W}_d^T$ is the matrix containing the principal components of the original d-dimensions.\n",
    "\n",
    "However due to information loss from the inital projection, the recovered data will be close to the original but not perfectly the same."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 4.\n",
    "\n",
    "> Can PCA be used to reduce the dimensionality of a highly nonlinear dataset?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "PCA can be used to reduce the dimensionality of a highly nonlinear dataset by implementing the kernel trick to PCA, also called Kernel PCA. \n",
    "\n",
    "Instead of finding a common hyperplane to project down onto, kPCA maps the dataset into a higher-dimensional feature space (sometimes even to $\\infty$-dimensional space). \n",
    "\n",
    "And then it projects down to the lower-dimension, safely reducing its dimensions without any loss of information."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 5.\n",
    "\n",
    "> Suppose you perform PCA on a 1,000-dimensional dataset, setting the explained variance ratio to 95%.\n",
    "\n",
    "> How many dimensions will the resulting dataset have?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The explained variance ratio is the proportion of the dataset's variance that lies along each principal component. There isn't enough information to determine how many dimensions the resulting dataset will have.\n",
    "\n",
    "If a dataset is linear, PCA can reduce it down to 1-D and preserve all of its variance. But if the dataset is a random scatter plot, the resulting dimensions would be 950-D at worst as it has to preserve 95% of the variance."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 6.\n",
    "\n",
    "> In what cases would you use vanilla PCA, Incremental PCA, Randomized PCA, or Kernel PCA?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "When to use the following PCA methods:\n",
    "\n",
    "- Vanilla PCA:\n",
    "    - Most small to medium training sets\n",
    "    - Fairly linear and not complex projections\n",
    "- Incremental PCA:\n",
    "    - Large training sets\n",
    "    - Online PCA (such as on the fly or new instance training)\n",
    "- Randomized PCA:\n",
    "    - Much faster training compared to vanilla PCA\n",
    "    - Okay with finding an approximation for the first d-principcal components\n",
    "    - (m or n > 500) and (d < 80% m or n)\n",
    "- Kernel PCA:\n",
    "    - Complex nonlinear projections\n",
    "    - Preserves clusters of instances after projection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 7.\n",
    "\n",
    "> How can you evaluate the performance of a dimensionality reduction algorithm on your dataset?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "You can evaluate the performance by performing an inverse transformation to project the reduced dataset back to its original dimensionality. Then compare the reconstructed dataset with the original by computing the mean squared distance error.\n",
    "\n",
    "A good dimensionality reduction algorithm would reduce the dimensions such that the algorithm runs faster and loses the least amount of information (ie. it minimizes the mean squared error between the reconstructed and original data)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 8.\n",
    "\n",
    "> Does it make any sense to chain two different dimensionality reduction algorithms?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "It would make sense to chain two different dimensionality reduction algorithms. The first can be used to remove empty dimensions so that the second can be used to transform the dataset without having to worry about the empty dimensions."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 9.\n",
    "\n",
    "> 1. Load the MNIST dataset (introduced in Chapter 3) and split it into a training set and a test set (take the first 60,000 instances for training, and the remaining 10,000 for testing).\n",
    "\n",
    "> 2. Train a Random Forest classifier on the dataset and time how long it takes, then evaluate the resulting model on the test set.\n",
    "\n",
    "> 3. Next, use PCA to reduce the dataset's dimensionality, with an explained variance ratio of 95%.\n",
    "\n",
    "> 4. Train a new Random Forest classifier on the reduced dataset and see how long it takes.\n",
    "\n",
    "> 5. Was training much faster?\n",
    "\n",
    "> 6. Next, evaluate the classifier on the test set.\n",
    "\n",
    "> 7. How does it compare to the previous classifier?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 10.\n",
    "\n",
    "> 1. Use t-SNE to reduce the MNIST dataset down to two dimensions and plot the result using Matplotlib.\n",
    "\n",
    "> 2. You can use a scatterplot using 10 different colors to represent each image's target class.\n",
    "\n",
    "> 3. Alternatively, you can replace each dot in the scatterplot with the corresponding instance's class (a digit from 0 to 9).\n",
    "\n",
    "> 4. Or even plot scaled-down versions of the digit images themselves.\n",
    "    >> Note: If you plot all digits, the visualization will be too cluttered, so you should either:  \n",
    "    >> - Draw a random sample.\n",
    "    >>\n",
    "    >> - Or plot an instance only if no other instance has already been plotted at a close distance.\n",
    "\n",
    "> 5. You should get a nice visualization with well-separated clusters of digits.\n",
    "\n",
    "> 6. Try using other dimensionality reduction algorithms such as PCA, LLE, or MDS and compare the resulting visualizations."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}